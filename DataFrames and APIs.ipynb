{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining structured web content and programmatic access\n",
    "\n",
    "In this notebook we will learn how to make use of readily structured data through dedicated application programming interfaces (APIs), how to authenticate and how to properly design requests (also called \"payload\") in order to retrieve large datasets.\n",
    "\n",
    "**Advantages** of APIs are that\n",
    "- access is legal and in most cases clearly and transparently regulated (e.g. 10,000 calls per day)\n",
    "- structuring through `requests` and `BeautifulSoup` not required\n",
    "- Python packages that simplify server-client interaction are available\n",
    "\n",
    "**Disadvantages** of APIs are that\n",
    "- we have to learn how APIs work and how we should interact with them (each API has some peculiarities and documentation is usually good, but sometimes not so...)\n",
    "- authentification may be required and access may not be free of charge \n",
    "\n",
    "We will\n",
    "- obtain data of a public statistical office such as the IMF or World Bank through the `pandas-datareader`\n",
    "- directly obtain a (ranking) table from a website such the [World Cube Association](https://www.worldcubeassociation.org/results/rankings/333/single)\n",
    "- learn how to use the Destatis/GENESIS Online service and API\n",
    "- learn how to use the Twitter API (in particular [Tweepy](https://www.tweepy.org/), a Python library for the Twitter API) and retrieve Tweets with GeoTags (i.e. coordinates) subject to specified geography and search terms\n",
    "- conduct some small analyses and visualise the results appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas-datareader\n",
      "  Downloading pandas_datareader-0.9.0-py3-none-any.whl (107 kB)\n",
      "Requirement already satisfied, skipping upgrade: pandas>=0.23 in c:\\users\\arlj\\anaconda3\\lib\\site-packages (from pandas-datareader) (1.1.3)\n",
      "Requirement already satisfied, skipping upgrade: requests>=2.19.0 in c:\\users\\arlj\\anaconda3\\lib\\site-packages (from pandas-datareader) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: lxml in c:\\users\\arlj\\anaconda3\\lib\\site-packages (from pandas-datareader) (4.6.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.15.4 in c:\\users\\arlj\\anaconda3\\lib\\site-packages (from pandas>=0.23->pandas-datareader) (1.19.2)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in c:\\users\\arlj\\anaconda3\\lib\\site-packages (from pandas>=0.23->pandas-datareader) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in c:\\users\\arlj\\anaconda3\\lib\\site-packages (from pandas>=0.23->pandas-datareader) (2020.1)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in c:\\users\\arlj\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas-datareader) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\users\\arlj\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas-datareader) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in c:\\users\\arlj\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas-datareader) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\arlj\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas-datareader) (1.25.11)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in c:\\users\\arlj\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=0.23->pandas-datareader) (1.15.0)\n",
      "Installing collected packages: pandas-datareader\n",
      "Successfully installed pandas-datareader-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas-datareader --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>unit</th>\n",
       "      <th>source</th>\n",
       "      <th>sourceNote</th>\n",
       "      <th>sourceOrganization</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9027</th>\n",
       "      <td>NV.SRV.DISC.CD</td>\n",
       "      <td>Discrepancy in GDP, value added (current US$)</td>\n",
       "      <td></td>\n",
       "      <td>Africa Development Indicators</td>\n",
       "      <td>This is the discrepancy included in the value ...</td>\n",
       "      <td>b'World Bank national accounts data, and OECD ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9155</th>\n",
       "      <td>NY.GDP.DISC.CD</td>\n",
       "      <td>Discrepancy in expenditure estimate of GDP (cu...</td>\n",
       "      <td></td>\n",
       "      <td>Africa Development Indicators</td>\n",
       "      <td>This is the discrepancy included in the ‘total...</td>\n",
       "      <td>b'World Bank national accounts data, and OECD ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9166</th>\n",
       "      <td>NY.GDP.MKTP.CD</td>\n",
       "      <td>GDP (current US$)</td>\n",
       "      <td></td>\n",
       "      <td>World Development Indicators</td>\n",
       "      <td>GDP at purchaser's prices is the sum of gross ...</td>\n",
       "      <td>b'World Bank national accounts data, and OECD ...</td>\n",
       "      <td>Economy &amp; Growth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9185</th>\n",
       "      <td>NY.GDP.PCAP.CD</td>\n",
       "      <td>GDP per capita (current US$)</td>\n",
       "      <td></td>\n",
       "      <td>World Development Indicators</td>\n",
       "      <td>GDP per capita is gross domestic product divid...</td>\n",
       "      <td>b'World Bank national accounts data, and OECD ...</td>\n",
       "      <td>Economy &amp; Growth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9292</th>\n",
       "      <td>NYGDPMKTPSACD</td>\n",
       "      <td>GDP,current US$,millions,seas. adj.,</td>\n",
       "      <td></td>\n",
       "      <td>Global Economic Monitor</td>\n",
       "      <td></td>\n",
       "      <td>b''</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                               name unit  \\\n",
       "9027  NV.SRV.DISC.CD      Discrepancy in GDP, value added (current US$)        \n",
       "9155  NY.GDP.DISC.CD  Discrepancy in expenditure estimate of GDP (cu...        \n",
       "9166  NY.GDP.MKTP.CD                                  GDP (current US$)        \n",
       "9185  NY.GDP.PCAP.CD                       GDP per capita (current US$)        \n",
       "9292   NYGDPMKTPSACD               GDP,current US$,millions,seas. adj.,        \n",
       "\n",
       "                             source  \\\n",
       "9027  Africa Development Indicators   \n",
       "9155  Africa Development Indicators   \n",
       "9166   World Development Indicators   \n",
       "9185   World Development Indicators   \n",
       "9292        Global Economic Monitor   \n",
       "\n",
       "                                             sourceNote  \\\n",
       "9027  This is the discrepancy included in the value ...   \n",
       "9155  This is the discrepancy included in the ‘total...   \n",
       "9166  GDP at purchaser's prices is the sum of gross ...   \n",
       "9185  GDP per capita is gross domestic product divid...   \n",
       "9292                                                      \n",
       "\n",
       "                                     sourceOrganization            topics  \n",
       "9027  b'World Bank national accounts data, and OECD ...                    \n",
       "9155  b'World Bank national accounts data, and OECD ...                    \n",
       "9166  b'World Bank national accounts data, and OECD ...  Economy & Growth  \n",
       "9185  b'World Bank national accounts data, and OECD ...  Economy & Growth  \n",
       "9292                                                b''                    "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas_datareader import wb\n",
    "search=wb.search('GDP.*current.*Us')\n",
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 60 entries, ('Germany', '2019') to ('Italy', '2000')\n",
      "Data columns (total 1 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   NY.GDP.MKTP.CD  60 non-null     float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 1.6+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60 entries, 0 to 59\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   country         60 non-null     object \n",
      " 1   year            60 non-null     object \n",
      " 2   NY.GDP.MKTP.CD  60 non-null     float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 1.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df = wb.download(indicator = 'NY.GDP.MKTP.CD', country = ['DE', 'FR', 'IT'],\n",
    "                start = 2000, end = 2019)\n",
    "df.info()\n",
    "df.groupby('country').describe()\n",
    "df2 = df.reset_index()\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'gdp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'gdp'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-407c25788ead>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcountry\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'country'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'country'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcountry\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'year'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'country'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcountry\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'gdp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcountry\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Year'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Nominal GDP (in US$)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'This is a so-so graph...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'gdp'"
     ]
    }
   ],
   "source": [
    "for country in df2['country'].unique():\n",
    "    plt.plot(df2[df2['country'] == country]['year'], df2[df2['country'] == country]['gdp'], label = country)\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Nominal GDP (in US$)')\n",
    "    plt.title('This is a so-so graph...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directly parsing `table` objects from HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall: %whos shows you the variables in name space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which nationality appears most frequently in the World Cube Association's ranking?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which nationality needed, on average, the **lowest** amount of time to solve a 3x3x3 cube? Sort the output in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many possible states/permutations, starting from the solved state, can a 3x3x3 Rubik's cube have? \n",
    "\n",
    "Hints:\n",
    "1. The centre squares are fixed (a plane rotation around these squares doesn't change the cube's state)\n",
    "2. There are eight corner pieces (with three colors on the side) and twelve edge pieces (with two colors on the side) which all revolve around the centre pieces\n",
    "3. There are six different colors\n",
    "4. We only look at \"legal\" states, i.e. those that can only be realised without assembling the cube (and therefore not violating Hint 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which result entry in the World Ranking table is the most recent one? Which one is the oldest one? Be as precise as possible! (Hint: You may have to combine your knowledge from scraping HTML files.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the expected value of `Result` conditional on `Nationality = 'Germany'`. Are the German contestants statistically significantly faster/slower in solving the cube than other contestants, based on `Nationality`? Does statistical significance change if you use robust standard errors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial libraries \n",
    "> (Note to myself: do GENESIS API first!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The installation procedure of spatial libraries for Python (on Windows) can be quite tedious but [this answer](https://stackoverflow.com/questions/51095970/install-python-geopandas-failed/51560940#51560940) on Stackoverflow (make sure to upvote ;)) and [this detailed instruction](https://geoffboeing.com/2014/09/using-geopandas-windows/) make it straight forward. You can also find the required wheels for Python 3.8 and 64-bit for offline `pip install` in this notebook's [repository](https://github.com/gerwolf/webscraping-workshop/tree/main/DataFrames%20and%20APIs). After this, you can simply `pip install geopandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = [16,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Destatis/GENESIS Online\n",
    "The GENESIS API is the web interface service by the Federal Statistical Office of Germany and is a good place to start learning how to interact programmatically with a server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a [comprehensive description/introduction](https://www-genesis.destatis.de/genesis/misc/GENESIS-Webservices_Einfuehrung.pdf) on the service, unfortunately in German only. To display the PDF inside Jupyter Notebook in Chrome you may have to enable the [PDF Viewer extension](https://chrome.google.com/webstore/detail/pdf-viewer/oemmndcbldboiebfnladdacbdfmadadm?utm_source=chrome-ntp-icon)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame, display\n",
    "filepath = \"https://www-genesis.destatis.de/genesis/misc/GENESIS-Webservices_Einfuehrung.pdf\"\n",
    "IFrame(filepath, width=980, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read about the `whoami` method (in Section 2.2). Do you have to authenticate? What does it return? How would you send a `request`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import genesis_config\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read about the `logincheck` method (in Section 2.2). Do you have to authenticate? What does it return? Construct a request object using string formatting, send a `request` (in English language) and print the request's status. What type is the response's `text` attribute?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a working connection to the GENESIS Online API we want to directly obtain an economic indicator, the private sector's savings rate on a quarterly basis, for instance. This `data` is usually stored in a `table` somewhere in the depths of a data warehouse and it is (unfortunately) necessary to familiarise yourself, at least partially, with the internal server's structure.\n",
    "1. In the documentation file search for the `tablefile` method (under Section 2.5 Data). When should it be used? What does it return?\n",
    "2. Which method should you use if you want to directly obtain a `chart`?\n",
    "3. Which method should you use if you want to directly obtain a regional `map`? Which parameter controls the image's resolution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Login to the [GENESIS Online user interface](https://www-genesis.destatis.de/genesis/online?Menu=Anmeldung#abreadcrumb). Familiarise yourself with the tables' structure and navigate to the National Accounts (at the central level) --> Private sector disposable income and savings at quarterly frequency. Which parameters in the request can you control?\n",
    "5. Which method would you choose if you want to directly obtain a `table` in some machine readable format, e.g. a `.csv` or `.xlsx` that you can read into `pandas`? Which output `formats` can you choose from? How do you include additional conditions matching particular values?\n",
    "6. Construct a `request` which contains the following specification:\n",
    "    - only seasonally and calendar-adjusted values (X13)\n",
    "    - all available years and quarters\n",
    "    - output format should be a `.xlsx` file\n",
    "7. Send the request, but directly through the `pandas.read_excel()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-twitter --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter\n",
    "import twitter_config\n",
    "\n",
    "api = twitter.Api(consumer_key = twitter_config.api_key ,\n",
    "                  consumer_secret = twitter_config.api_secret_key,\n",
    "                  access_token_key = twitter_config.access_token,\n",
    "                  access_token_secret = twitter_config.access_token_secret,\n",
    "                  tweet_mode = 'extended',\n",
    "                  sleep_on_rate_limit = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us query a free-text-search using the hashtag `#gameofthrones`. Which function would you use? Limit the maximum amount of response elements to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which type is the output object? Which type have the output object's elements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tweepy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import json\n",
    "import twitter_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(twitter_config.api_key, twitter_config.api_secret_key)\n",
    "auth.set_access_token(twitter_config.access_token, twitter_config.access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Tweepy` is great for retrieving additional info on Tweets such as GeoLocation (only for those where users have enabled the feature, or not consciously disabled it)\n",
    "- We will run a small analysis of the spatial distribution of recent Tweets in Germany\n",
    "- The common finding (also known in the academic and non-academic literature) is that the data quality decreases substantially once we condition those observations on specific keywords\n",
    "> Please note that Twitter’s search service and, by extension, the Search API is not meant to be an exhaustive source of Tweets. Not all Tweets will be indexed or made available via the search interface. (From the [official Twitter API documentation](https://developer.twitter.com/en/docs/twitter-api/v1/tweets/search/api-reference/get-search-tweets))\n",
    "\n",
    "Your task now: familiarise yourself with the [`Twitter ` API](https://developer.twitter.com/en/docs/twitter-api/v1) and [`Tweepy` Python](https://docs.tweepy.org/en/v3.10.0/index.html) implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"980\"\n",
       "            height=\"400\"\n",
       "            src=\"https://docs.tweepy.org/en/v3.10.0/index.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x254859ff430>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "url = 'https://docs.tweepy.org/en/v3.10.0/index.html'\n",
    "IFrame(url, width=980, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Which `Tweepy` version have you installed?\n",
    "2. Which function would you use to send a search query?\n",
    "3. Which function in `Tweepy` facilitates pagination?\n",
    "4. Which fields contain [spatial](https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/geo) information?\n",
    "5. Identify the internal country code of `Germany`, i.e. its `id`.\n",
    "6. How would you [construct a query](https://developer.twitter.com/en/docs/twitter-api/v1/tweets/search/api-reference/get-search-tweets) that specifies a search term, the language and the number of Tweets shown per page?\n",
    "\n",
    "Note there are [rate limits](https://developer.twitter.com/en/docs/twitter-api/rate-limits)! For example, include `time.sleep(15 * 60)` in case your rate limit was reached when running more comprehensive searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example query\n",
    "\n",
    "header = {\"q\": \"place:fdcd221ac44fa326\", \"lang\": \"de\", \"tweet_mode\": \"extended\", \"count\": 100}\n",
    "\n",
    "# Note: \"count\":100 is the maximum of returned Tweets per request/item in the standard Twitter API\n",
    "# You can paginate either per item (i.e. individual request) or pages of results \n",
    "# https://docs.tweepy.org/en/latest/cursor_tutorial.html\n",
    "# The Cursor() function ignores the 'count' parameter in the query, the limit is defined in the items() function instead\n",
    "\n",
    "batch_tweets = tweepy.Cursor(api.search, **header)\n",
    "\n",
    "noOfSearch = 200\n",
    "\n",
    "batch_items = batch_tweets.items(noOfSearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_list = [i._json for i in batch_items] # underscore means 'intended for internal use'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function which takes as input arguments a (not hardcoded) `place_id`, `language` and `tweet_mode` (which you set to \"extended\" by default such that you query the full, untruncated text content of the Tweets) and returns a **list of dictionaries**. The goal is to obtain a as-complete-as-possible collection of recent Tweets in Germany **without specifying a `key word`**. In order to maximize the number of Tweets you receive, stack the `.Cursor()` object inside of a for-loop. Save the resulting output to your local directory as a `.json` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have the raw output, determine the total number of unique Tweets, i.e. `ids`.\n",
    "You can use a dictionary comprehension (similar to list comprehensions) to achieve that since duplicate keys are not allowed in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = { tweet['id'] : tweet for tweet in bunches }\n",
    "len(unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify all Tweets (elements) which value associated with the key `coordinates` is different from `None`. Assign the result to an object `matches`. How does the content of this object compare to the \"unfiltered\" data container `unique`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for matching elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get elements in this format:\n",
    "\n",
    "```\n",
    "{1382787792535703552: {'created_at': 'Thu Apr 15 20:07:55 +0000 2021',\n",
    "  'id': 1382787792535703552,\n",
    "  'id_str': '1382787792535703552',\n",
    "  'full_text': '@bennai_m @JoueursDZ @DZfoot Ya sehr gut geschossen Grosse Verantwortung',\n",
    "  'truncated': False,\n",
    "  'display_text_range': [29, 72],\n",
    "  'entities': {'hashtags': [],\n",
    "   'symbols': [],\n",
    "   'user_mentions': [{'screen_name': 'bennai_m',\n",
    "     'name': 'MBennai',\n",
    "     'id': 1157689821969756161,\n",
    "     'id_str': '1157689821969756161',\n",
    "     'indices': [0, 9]},\n",
    "    {'screen_name': 'JoueursDZ',\n",
    "     'name': 'JDZ Football',\n",
    "     'id': 1177267711157690371,\n",
    "     'id_str': '1177267711157690371',\n",
    "     'indices': [10, 20]},\n",
    "    {'screen_name': 'DZfoot',\n",
    "     'name': 'DZfoot',\n",
    "     'id': 296303972,\n",
    "     'id_str': '296303972',\n",
    "     'indices': [21, 28]}],\n",
    "   'urls': []},\n",
    "  'metadata': {'iso_language_code': 'de', 'result_type': 'recent'},\n",
    "  'source': '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>',\n",
    "  'in_reply_to_status_id': 1382781123978223624,\n",
    "  'in_reply_to_status_id_str': '1382781123978223624',\n",
    "  'in_reply_to_user_id': 1157689821969756161,\n",
    "  'in_reply_to_user_id_str': '1157689821969756161',\n",
    "  'in_reply_to_screen_name': 'bennai_m',\n",
    "  'user': {'id': 1370800515295100933,\n",
    "   'id_str': '1370800515295100933',\n",
    "   'name': 'Tassilli Hoggar',\n",
    "   'screen_name': 'TassilliHoggar',\n",
    "   'location': '',\n",
    "   'description': 'sports',\n",
    "   'url': None,\n",
    "   'entities': {'description': {'urls': []}},\n",
    "   'protected': False,\n",
    "   'followers_count': 17,\n",
    "   'friends_count': 113,\n",
    "   'listed_count': 0,\n",
    "   'created_at': 'Sat Mar 13 18:15:23 +0000 2021',\n",
    "   'favourites_count': 427,\n",
    "   'utc_offset': None,\n",
    "   'time_zone': None,\n",
    "   'geo_enabled': True,\n",
    "   'verified': False,\n",
    "   'statuses_count': 959,\n",
    "   'lang': None,\n",
    "   'contributors_enabled': False,\n",
    "   'is_translator': False,\n",
    "   'is_translation_enabled': False,\n",
    "   'profile_background_color': 'F5F8FA',\n",
    "   'profile_background_image_url': None,\n",
    "   'profile_background_image_url_https': None,\n",
    "   'profile_background_tile': False,\n",
    "   'profile_image_url': 'http://pbs.twimg.com/profile_images/1370801015902064643/BCSHPcOg_normal.jpg',\n",
    "   'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1370801015902064643/BCSHPcOg_normal.jpg',\n",
    "   'profile_link_color': '1DA1F2',\n",
    "   'profile_sidebar_border_color': 'C0DEED',\n",
    "   'profile_sidebar_fill_color': 'DDEEF6',\n",
    "   'profile_text_color': '333333',\n",
    "   'profile_use_background_image': True,\n",
    "   'has_extended_profile': True,\n",
    "   'default_profile': True,\n",
    "   'default_profile_image': False,\n",
    "   'following': False,\n",
    "   'follow_request_sent': False,\n",
    "   'notifications': False,\n",
    "   'translator_type': 'none'},\n",
    "  'geo': None,\n",
    "  'coordinates': None,\n",
    "  'place': {'id': '5bcd72da50f0ee77',\n",
    "   'url': 'https://api.twitter.com/1.1/geo/id/5bcd72da50f0ee77.json',\n",
    "   'place_type': 'city',\n",
    "   'name': 'Hamburg',\n",
    "   'full_name': 'Hamburg, Germany',\n",
    "   'country_code': 'DE',\n",
    "   'country': 'Germany',\n",
    "   'contained_within': [],\n",
    "   'bounding_box': {'type': 'Polygon',\n",
    "    'coordinates': [[[8.4201604, 53.395118],\n",
    "      [10.325199, 53.395118],\n",
    "      [10.325199, 53.9646546],\n",
    "      [8.4201604, 53.9646546]]]},\n",
    "   'attributes': {}},\n",
    "  'contributors': None,\n",
    "  'is_quote_status': False,\n",
    "  'retweet_count': 0,\n",
    "  'favorite_count': 0,\n",
    "  'favorited': False,\n",
    "  'retweeted': False,\n",
    "  'lang': 'de'}}\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point, Polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're using a spatial library to process those appropriate data fields. The coordinates are in rectangular form and we would like to collapse them to a single point (e.g. to increase the accuracy). \n",
    "- First you need to convert the raw rectangular coordinates into a shape (use `Polygon()`), obtain the centroid from the resulting object and separate it into `longitude` and `latitude`. \n",
    "- Then combine the two coordinates to a `Point()` coordinates object.\n",
    "- Extract the following key-values from the `matches` data container:\n",
    "    - key\n",
    "    - timestamp of creation\n",
    "    - full Tweet text\n",
    "    - the user's registered name\n",
    "    - the user's nickname/alias as shown on Twitter\n",
    "    - the place's ID\n",
    "    - the place's name\n",
    "    - the place's country code\n",
    "    - the place's country name\n",
    "    - the place's bounding box' coordinates\n",
    "    - the place's centroid's coordinates (as Shapely object)\n",
    "    - the Tweet's number of Retweets\n",
    "    - the Tweet's number of likes/favorites\n",
    "    - the user's location (e.g. checked in @ Universität Potsdam)\n",
    "    - the number of user's followers\n",
    "    - the number of user's friends\n",
    "    - the registration date of the user's account\n",
    "    - a complete URL that leads to the original Tweet (Hint: it's a combination of two other fields from above, use string formatting)\n",
    "\n",
    "The output should have the following format:\n",
    "\n",
    "```\n",
    "{'Tweet ID': 1382787792535703552,\n",
    " 'Created at': Timestamp('2021-04-15 20:07:55+0000', tz='UTC'),\n",
    " 'Full Text': '@bennai_m @JoueursDZ @DZfoot Ya sehr gut geschossen Grosse Verantwortung',\n",
    " 'User Name': 'Tassilli Hoggar',\n",
    " 'User Alias': 'TassilliHoggar',\n",
    " 'Place ID': '5bcd72da50f0ee77',\n",
    " 'Place Name': 'Hamburg',\n",
    " 'Country Code': 'DE',\n",
    " 'Country Name': 'Germany',\n",
    " 'Bounding Box': [[8.4201604, 53.395118],\n",
    "  [10.325199, 53.395118],\n",
    "  [10.325199, 53.9646546],\n",
    "  [8.4201604, 53.9646546]],\n",
    " 'Tweet Coordinates': <shapely.geometry.point.Point at 0x292c8039f10>,\n",
    " 'Retweet Count': 0,\n",
    " 'Favorite Count': 0,\n",
    " 'User Location': '',\n",
    " 'User Followers': 17,\n",
    " 'User Friends': 113,\n",
    " 'Registration Date': 'Sat Mar 13 18:15:23 +0000 2021',\n",
    " 'Tweet URL': 'https://twitter.com/TassilliHoggar/status/1382787792535703552'}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for parsing\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results_list)\n",
    "gdf = gpd.GeoDataFrame(results_df, geometry=results_df['Tweet Coordinates'])\n",
    "gdf.crs = \"epsg=4326\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapbox_access_token = open(\"mapbox_token.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for creating the Plotly graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "palette = sns.color_palette(None, 11).as_hex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# germany_borders = gpd.read_file(\"Bundeslaender_2016_ew.shp\")\n",
    "# You can find it here: https://opendata-esri-de.opendata.arcgis.com/datasets/b8d0cc7735774bed8e6df1c5410394a4_0?geometry=-31.360%2C46.270%2C52.268%2C55.886"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "germany_borders = gpd.read_file(\"https://opendata.arcgis.com/datasets/b8d0cc7735774bed8e6df1c5410394a4_0.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/64200595/geopandas-overlay-intersection-returns-zero-rows THANK YOU!\n",
    "\n",
    "# Multiple solutions: https://gis.stackexchange.com/questions/208546/check-if-a-point-falls-within-a-multipolygon-with-python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can the clusters and memberships you assigned before be meaningfully interpreted? How many Tweets (as percentage of all per state) were classified into the cluster with `cluster id = 8`? From which state does those cluster members most likely originate from? Confirm your assertion by looking at the map you created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
