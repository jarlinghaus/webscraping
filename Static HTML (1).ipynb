{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00505bd6",
   "metadata": {},
   "source": [
    "# Obtaining, parsing and structuring static HTML websites\n",
    "\n",
    "In this notebook we will learn how to scrape basic static, i.e. non-interactive HTML-based websites. We will\n",
    "- obtain the HTML raw content using the `requests` module\n",
    "- convert the raw HTML into a format that is easier to search, or parse, using the `BeautifulSoup` module\n",
    "- learn how to identify the elements of interest in the raw HTML using the browser's inspect functionality and the CSS SelectorGadget\n",
    "- construct a table, or dataframe, with the popular table calculation module `pandas` and store the output locally in a standard spreadsheet format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb6a337",
   "metadata": {},
   "source": [
    "1. Open the Anaconda Prompt and install the module `requests`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f7c5ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\wolfg\\anaconda3\\envs\\webscraping\\lib\\site-packages (2.25.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wolfg\\anaconda3\\envs\\webscraping\\lib\\site-packages (from requests) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\wolfg\\anaconda3\\envs\\webscraping\\lib\\site-packages (from requests) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\wolfg\\anaconda3\\envs\\webscraping\\lib\\site-packages (from requests) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\wolfg\\anaconda3\\envs\\webscraping\\lib\\site-packages (from requests) (2.10)\n"
     ]
    }
   ],
   "source": [
    "! pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f0033dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "245f6de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 'https://www.uni-potsdam.de/de/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c7ca65",
   "metadata": {},
   "source": [
    "2. What data type is the object `seed`? How can you check?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d94dfd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6577ae4e",
   "metadata": {},
   "source": [
    "3. Is this domain (https://www.uni-potsdam.de/de/nachrichten.html) an admissible path? Hint: Check the `robots.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39c15aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = requests.get(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ba7a26",
   "metadata": {},
   "source": [
    "4. Was the request successful? How can you check the status? Hint: Check the available methods by using Jupyter's auto-complete functionality, i.e. type a dot at the end of the object you're investigating followed by <kbd>Tab</kbd>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e29a831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2239b1",
   "metadata": {},
   "source": [
    "5. Which method could be most informative w.r.t. actual content? How many characters long is the raw HTML file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae92d257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64632"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(html.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bc53b3",
   "metadata": {},
   "source": [
    "6. Display the first 518 characters of the `html` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a05bce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html><html dir=\"ltr\" lang=\"de-DE\"><head><meta charset=\"utf-8\"><!-- benaja - web solutions (www.benaja-websolutions.com) Markus Meier, Roland Brandt und Tobias Gaertner GbR This website is powered by TYPO3 - inspiring people to share! TYPO3 is a free open source Content Management Framework initially created by Kasper Skaarhoj and licensed under GNU/GPL. TYPO3 is copyright 1998-2021 of Kasper Skaarhoj. Extensions are copyright of their respective owners. Information and contribution at https://typo3.org/'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html.text[:518]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32fe467",
   "metadata": {},
   "source": [
    "7. Display meta information on the origin of the HTTP request, e.g. date. Note that it is possible to specify the `user-agent` that the server receives and provides the response (website representation) such that it optimised, e.g. Desktop vs. mobile. If it's not specified, the request will be sent using default values (potentially) containing information about your operating system, screen resolution, keyboard language, IP address and many more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23744022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date': 'Thu, 15 Apr 2021 12:27:42 GMT', 'Server': 'Apache/2.4.29 (Ubuntu)', 'Vary': 'Accept-Encoding', 'Last-Modified': 'Thu, 15 Apr 2021 12:25:33 GMT', 'Accept-Ranges': 'bytes', 'Content-Length': '11841', 'Cache-Control': 'max-age=0', 'Expires': 'Thu, 15 Apr 2021 12:27:42 GMT', 'X-UA-Compatible': 'IE=edge', 'X-Content-Type-Options': 'nosniff', 'Content-Encoding': 'gzip', 'Keep-Alive': 'timeout=5, max=100', 'Connection': 'Keep-Alive', 'Content-Type': 'text/html; charset=utf-8'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html.headers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5ee423",
   "metadata": {},
   "source": [
    "The cell below saves the HTML object's text attribute in HTML format locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce1d0633",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Uni_Potsdam.html', 'w', encoding='utf-8') as f:\n",
    "    \n",
    "    f.write(html.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da94971",
   "metadata": {},
   "source": [
    "8. Install the module `BeautifulSoup` via `pip install beautifulsoup4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "909ff5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c2f8164",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37c98e9",
   "metadata": {},
   "source": [
    "9. Parse the BeautifulSoup object `soup` for all Affiliate Links. Hint: In a HTML document all elements that lead to another domain are indicated by an `a` and follow the structure `<a href=\"...\", ... >text</a>`. Hint: Use `soup`'s method `find_all()` where the input argument is the elements' prefix. What object type is the output? Can you iterate over it? How many elements of an Affiliate Link type are contained in the HTML file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b517d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(soup.find_all('a'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc92243",
   "metadata": {},
   "source": [
    "10. Convert the BeautifulSoup object into a \"plain\" Python list object containing the elements' **text** attributes by iterating over it. Hint: Instantiate an empty `list` object, write a for-loop and `append` each element to the list object. You may also remove any unwanted whitespaces by using the `strip` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7aae91c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_list = []\n",
    "\n",
    "for link in soup.find_all('a'):\n",
    "    \n",
    "    empty_list.append(link.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11b98dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ãœbersicht'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('a')[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208a5535",
   "metadata": {},
   "source": [
    "#### Pro-Tipp\n",
    "Instead of explicitly writing a for-loop when disentangling specific objects from an aggregate object you can use Python's built-in `map` and `lambda` functions as a one-liner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28dcb515",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = list(map(lambda x: x.text.strip(), soup.find_all('a')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a6893c",
   "metadata": {},
   "source": [
    "11. Identify the element which text attribute's value is equal to \"alle Artikel\". Return the element's position (`index`) within the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24f2330e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220\n"
     ]
    }
   ],
   "source": [
    "all_news_index = results_list.index('alle Artikel')\n",
    "print(all_news_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6fd787",
   "metadata": {},
   "source": [
    "12. Obtain this element's value of the `href` attribute. It should be an URL pointing at the domain where the news at UniversitÃ¤t Potsdam are collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "274d63bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.uni-potsdam.de/nachrichten.html\n"
     ]
    }
   ],
   "source": [
    "new_seed = soup.find_all('a')[all_news_index].get('href')\n",
    "print(new_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c697a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c0a9f9f",
   "metadata": {},
   "source": [
    "13. Write a function which takes a String-type object (e.g. an URL) as input and returns a readily parse-able `BeautifulSoup` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c45fd447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def URL_to_BS(url):\n",
    "    \n",
    "    html = requests.get(url)\n",
    "    soup = BeautifulSoup(html.text, \"html.parser\")\n",
    "    \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "76d13dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_soup = URL_to_BS(new_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d7de833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.uni-potsdam.de/nachrichten.html'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23f6564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_soup = URL_to_BS(new_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02264a81",
   "metadata": {},
   "source": [
    "14. Open the `new_seed` URL in your browser and enable the CSS SelectorGadget. Highlight the box containing the first article. The other, similar boxes should be highlighted as well. Copy the identified CSS selector and parse through the `news_soup` object but this time over elements corresponding to the CSS selector you found (use `.select()` instead of `find_all()`). Store the subset of elements in a list. You can achieve all of this in one line of code. How many items does this list contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8f3b3977",
   "metadata": {},
   "outputs": [],
   "source": [
    "css_element = '.up-news-list-item'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "32c8a0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"up-news-list-item\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\"><div class=\"up-news-list-item-image\"><a href=\"/de/nachrichten/detail/2021-04-15-studio-days-2021-digitale-studienorientierungswoche-der-staatlichen-brandenburgischen\" title=\"Studiâ€™O Days 2021 â€“ digitale Studienorientierungswoche der staatlichen brandenburgischen Hochschulen\"><div class=\"news-img-wrap\"><a href=\"/de/nachrichten/detail/2021-04-15-studio-days-2021-digitale-studienorientierungswoche-der-staatlichen-brandenburgischen\" title=\"Studiâ€™O Days 2021 â€“ digitale Studienorientierungswoche der staatlichen brandenburgischen Hochschulen\"><img alt=\"Matthias Friel, Netzwerk Studienorientierung Brandenburg\" height=\"140\" src=\"/fileadmin/_processed_/c/2/csm_2021-04_Cover_StudiODays_PM_ce48bf3905.jpg\" width=\"270\"/></a></div></a></div><div class=\"up-news-list-item-text\"><a href=\"/de/nachrichten/detail/2021-04-15-studio-days-2021-digitale-studienorientierungswoche-der-staatlichen-brandenburgischen\" title=\"Studiâ€™O Days 2021 â€“ digitale Studienorientierungswoche der staatlichen brandenburgischen Hochschulen\"><h2>Studiâ€™O Days 2021 â€“ digitale Studienorientierungswoche der staatlichen brandenburgischen Hochschulen</h2></a><div class=\"up-news-list-published\"><time datetime=\"2021-04-15\"> 15.04.2021 </time></div><span class=\"up-news-list-text\"> Das Netzwerk Studienorientierung Brandenburg lÃ¤dt vom 26. bis 30. April 2021 zur digitalen Studienorientierungswoche ein. Unter dem Motto â€žFÃ¼nf Tage,... </span><span class=\"up-news-list-morelink\"><a class=\"more\" href=\"/de/nachrichten/detail/2021-04-15-studio-days-2021-digitale-studienorientierungswoche-der-staatlichen-brandenburgischen\" title=\"Studiâ€™O Days 2021 â€“ digitale Studienorientierungswoche der staatlichen brandenburgischen Hochschulen\"> mehr </a></span></div><div class=\"up-clear\"></div></div>,\n",
       " <div class=\"up-news-list-item\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\"><div class=\"up-news-list-item-image\"><a href=\"/de/nachrichten/detail/2021-04-15-hoppla-jetzt-kommt-koppla-die-revolution-fuers-handwerk\" title=\"Hoppla! Jetzt kommt Koppla! â€“ Die Revolution fÃ¼rs Handwerk\"><div class=\"news-img-wrap\"><a href=\"/de/nachrichten/detail/2021-04-15-hoppla-jetzt-kommt-koppla-die-revolution-fuers-handwerk\" title=\"Hoppla! Jetzt kommt Koppla! â€“ Die Revolution fÃ¼rs Handwerk\"><img alt=\"Lasse Steffen, Marco Trippler und Jerome Lange (v.l.n.r.) | Foto: Thomas Roese\" height=\"140\" src=\"/fileadmin/_processed_/0/9/csm_2021-04_Koppla_DSC2021_Thomas_Roese_92315a26d2.jpg\" title=\"Lasse Steffen, Marco Trippler und Jerome Lange (v.l.n.r.) | Foto: Thomas Roese\" width=\"270\"/></a></div></a></div><div class=\"up-news-list-item-text\"><a href=\"/de/nachrichten/detail/2021-04-15-hoppla-jetzt-kommt-koppla-die-revolution-fuers-handwerk\" title=\"Hoppla! Jetzt kommt Koppla! â€“ Die Revolution fÃ¼rs Handwerk\"><h2>Hoppla! Jetzt kommt Koppla! â€“ Die Revolution fÃ¼rs Handwerk</h2></a><div class=\"up-news-list-published\"><time datetime=\"2021-04-15\"> 15.04.2021 </time></div><span class=\"up-news-list-text\"> â€žWir wollen, dass jede Handwerkerin und jeder Handwerker mit unserer Software arbeitet â€“ weil sie leicht zu bedienen ist und viele Prozesse... </span><span class=\"up-news-list-morelink\"><a class=\"more\" href=\"/de/nachrichten/detail/2021-04-15-hoppla-jetzt-kommt-koppla-die-revolution-fuers-handwerk\" title=\"Hoppla! Jetzt kommt Koppla! â€“ Die Revolution fÃ¼rs Handwerk\"> mehr </a></span></div><div class=\"up-clear\"></div></div>,\n",
       " <div class=\"up-news-list-item\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\"><div class=\"up-news-list-item-image\"><a href=\"/de/nachrichten/detail/2021-04-13-science-fiction-experimentelle-kooperation-von-germanistik-und-food4future\" title=\"Science / Fiction â€“ Experimentelle Kooperation von Germanistik und food4future\"><div class=\"news-img-wrap\"><a href=\"/de/nachrichten/detail/2021-04-13-science-fiction-experimentelle-kooperation-von-germanistik-und-food4future\" title=\"Science / Fiction â€“ Experimentelle Kooperation von Germanistik und food4future\"><img alt=\"Buch: ArtsyBunnies via freepik.com / f4f-Vision: headland fÃ¼r food4future\" height=\"140\" src=\"/fileadmin/_processed_/c/c/csm_2021-04_UP_LitWiss_x_food4future_82f0052b19.jpg\" width=\"270\"/></a></div></a></div><div class=\"up-news-list-item-text\"><a href=\"/de/nachrichten/detail/2021-04-13-science-fiction-experimentelle-kooperation-von-germanistik-und-food4future\" title=\"Science / Fiction â€“ Experimentelle Kooperation von Germanistik und food4future\"><h2>Science / Fiction â€“ Experimentelle Kooperation von Germanistik und food4future</h2></a><div class=\"up-news-list-published\"><time datetime=\"2021-04-13\"> 13.04.2021 </time></div><span class=\"up-news-list-text\"> Kann Science Fiction-Literatur Inspirationen fÃ¼r innovative AnsÃ¤tze in der Forschung zur Nahrungsmittel- und Agrarproduktion liefern? Denken wir in... </span><span class=\"up-news-list-morelink\"><a class=\"more\" href=\"/de/nachrichten/detail/2021-04-13-science-fiction-experimentelle-kooperation-von-germanistik-und-food4future\" title=\"Science / Fiction â€“ Experimentelle Kooperation von Germanistik und food4future\"> mehr </a></span></div><div class=\"up-clear\"></div></div>,\n",
       " <div class=\"up-news-list-item\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\"><div class=\"up-news-list-item-image\"><a href=\"/de/nachrichten/detail/2021-04-13-wir-waren-exotisch-der-linguist-gisbert-fanselow-und-der-psychologe-reinhold-klie\" title=\"â€žWir waren exotisch!â€œ â€“ Der Linguist Gisbert Fanselow und der Psychologe Reinhold Kliegl im GesprÃ¤ch Ã¼ber lÃ¶chrige DÃ¤cher, schwierige AnfÃ¤nge und die richtigen Forschungsfragen\"><div class=\"news-img-wrap\"><a href=\"/de/nachrichten/detail/2021-04-13-wir-waren-exotisch-der-linguist-gisbert-fanselow-und-der-psychologe-reinhold-klie\" title=\"â€žWir waren exotisch!â€œ â€“ Der Linguist Gisbert Fanselow und der Psychologe Reinhold Kliegl im GesprÃ¤ch Ã¼ber lÃ¶chrige DÃ¤cher, schwierige AnfÃ¤nge und die richtigen Forschungsfragen\"><img alt=\"In gemeinsamer Forschung vertieft wie am ersten Tag â€“ Linguist Gisbert Fanselow und Psychologie Reinhold Kliegl, 2014 | Foto: ZIM\" height=\"140\" src=\"/fileadmin/_processed_/8/a/csm_2021-04_Fanselow_Kliegl_2014_Foto_ZIM_a1e3331679.jpg\" title=\"In gemeinsamer Forschung vertieft wie am ersten Tag â€“ Linguist Gisbert Fanselow und Psychologie Reinhold Kliegl, 2014 | Foto: ZIM\" width=\"270\"/></a></div></a></div><div class=\"up-news-list-item-text\"><a href=\"/de/nachrichten/detail/2021-04-13-wir-waren-exotisch-der-linguist-gisbert-fanselow-und-der-psychologe-reinhold-klie\" title=\"â€žWir waren exotisch!â€œ â€“ Der Linguist Gisbert Fanselow und der Psychologe Reinhold Kliegl im GesprÃ¤ch Ã¼ber lÃ¶chrige DÃ¤cher, schwierige AnfÃ¤nge und die richtigen Forschungsfragen\"><h2>â€žWir waren exotisch!â€œ â€“ Der Linguist Gisbert Fanselow und der Psychologe Reinhold Kliegl im GesprÃ¤ch Ã¼ber lÃ¶chrige DÃ¤cher, schwierige AnfÃ¤nge und die richtigen Forschungsfragen</h2></a><div class=\"up-news-list-published\"><time datetime=\"2021-04-13\"> 13.04.2021 </time></div><span class=\"up-news-list-text\"> Die Kognitionswissenschaften gehÃ¶ren zu den Forschungsschwerpunkten der UniversitÃ¤t Potsdam (UP) und haben sich national wie international einen Namen... </span><span class=\"up-news-list-morelink\"><a class=\"more\" href=\"/de/nachrichten/detail/2021-04-13-wir-waren-exotisch-der-linguist-gisbert-fanselow-und-der-psychologe-reinhold-klie\" title=\"â€žWir waren exotisch!â€œ â€“ Der Linguist Gisbert Fanselow und der Psychologe Reinhold Kliegl im GesprÃ¤ch Ã¼ber lÃ¶chrige DÃ¤cher, schwierige AnfÃ¤nge und die richtigen Forschungsfragen\"> mehr </a></span></div><div class=\"up-clear\"></div></div>,\n",
       " <div class=\"up-news-list-item\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\"><div class=\"up-news-list-item-image\"><a href=\"/de/nachrichten/detail/2021-04-12-eine-bruecke-in-den-arbeitsmarkt-warum-betriebswirtin-kristina-nistor-noch-einmal-zur-uni-g\" title=\"Eine BrÃ¼cke in den Arbeitsmarkt: Warum Betriebswirtin Kristina Nistor noch einmal zur Uni ging\"><div class=\"news-img-wrap\"><a href=\"/de/nachrichten/detail/2021-04-12-eine-bruecke-in-den-arbeitsmarkt-warum-betriebswirtin-kristina-nistor-noch-einmal-zur-uni-g\" title=\"Eine BrÃ¼cke in den Arbeitsmarkt: Warum Betriebswirtin Kristina Nistor noch einmal zur Uni ging\"><img alt=\"Kristina Nistor absolvierte an der Uni eine BrÃ¼ckenmaÃŸnahme fÃ¼r Hochschulabsolventen mit Migrationsgeschichte | Foto: Nadja Bossmann\" height=\"140\" src=\"/fileadmin/_processed_/3/b/csm_2021-03_Portraet_Kristina_Nistor_Bossmann_99e28252e8.jpg\" title=\"Kristina Nistor absolvierte an der Uni eine BrÃ¼ckenmaÃŸnahme fÃ¼r Hochschulabsolventen mit Migrationsgeschichte | Foto: Nadja Bossmann\" width=\"270\"/></a></div></a></div><div class=\"up-news-list-item-text\"><a href=\"/de/nachrichten/detail/2021-04-12-eine-bruecke-in-den-arbeitsmarkt-warum-betriebswirtin-kristina-nistor-noch-einmal-zur-uni-g\" title=\"Eine BrÃ¼cke in den Arbeitsmarkt: Warum Betriebswirtin Kristina Nistor noch einmal zur Uni ging\"><h2>Eine BrÃ¼cke in den Arbeitsmarkt: Warum Betriebswirtin Kristina Nistor noch einmal zur Uni ging</h2></a><div class=\"up-news-list-published\"><time datetime=\"2021-04-12\"> 12.04.2021 </time></div><span class=\"up-news-list-text\"> Vor zwei Jahren hat Kristina Nistor an der UniversitÃ¤t Potsdam eine BrÃ¼ckenmaÃŸnahme absolviert, die arbeitslosen Hochschulabsolventen mit... </span><span class=\"up-news-list-morelink\"><a class=\"more\" href=\"/de/nachrichten/detail/2021-04-12-eine-bruecke-in-den-arbeitsmarkt-warum-betriebswirtin-kristina-nistor-noch-einmal-zur-uni-g\" title=\"Eine BrÃ¼cke in den Arbeitsmarkt: Warum Betriebswirtin Kristina Nistor noch einmal zur Uni ging\"> mehr </a></span></div><div class=\"up-clear\"></div></div>,\n",
       " <div class=\"up-news-list-item\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\"><div class=\"up-news-list-item-image\"><a href=\"/de/nachrichten/detail/2021-04-08-die-klima-uhr-tickt-der-wirtschaftswissenschaftler-matthias-kalkuhl-erforscht-wie-die-k\" title=\"Die Klima-Uhr tickt â€“ Der Wirtschaftswissenschaftler Matthias Kalkuhl erforscht, wie die Klimawende gelingen kann\"><div class=\"news-img-wrap\"><a href=\"/de/nachrichten/detail/2021-04-08-die-klima-uhr-tickt-der-wirtschaftswissenschaftler-matthias-kalkuhl-erforscht-wie-die-k\" title=\"Die Klima-Uhr tickt â€“ Der Wirtschaftswissenschaftler Matthias Kalkuhl erforscht, wie die Klimawende gelingen kann\"><img alt=\"Prof. Matthias Kalkuhl | Foto: Tobias Hopfgarten\" height=\"140\" src=\"/fileadmin/_processed_/a/1/csm_2020-09_Kalkuhl_HeikeKampeInterview_TobiasHopfgarten_DSC6276_b6a03de871.jpg\" title=\"Prof. Matthias Kalkuhl | Foto: Tobias Hopfgarten\" width=\"270\"/></a></div></a></div><div class=\"up-news-list-item-text\"><a href=\"/de/nachrichten/detail/2021-04-08-die-klima-uhr-tickt-der-wirtschaftswissenschaftler-matthias-kalkuhl-erforscht-wie-die-k\" title=\"Die Klima-Uhr tickt â€“ Der Wirtschaftswissenschaftler Matthias Kalkuhl erforscht, wie die Klimawende gelingen kann\"><h2>Die Klima-Uhr tickt â€“ Der Wirtschaftswissenschaftler Matthias Kalkuhl erforscht, wie die Klimawende gelingen kann</h2></a><div class=\"up-news-list-published\"><time datetime=\"2021-04-08\"> 08.04.2021 </time></div><span class=\"up-news-list-text\"> Jeden Morgen, wenn Matthias Kalkuhl zu seinem Arbeitsplatz am Mercator Research Institute on Global Commons and Climate Change (MCC) in Berlin fÃ¤hrt,... </span><span class=\"up-news-list-morelink\"><a class=\"more\" href=\"/de/nachrichten/detail/2021-04-08-die-klima-uhr-tickt-der-wirtschaftswissenschaftler-matthias-kalkuhl-erforscht-wie-die-k\" title=\"Die Klima-Uhr tickt â€“ Der Wirtschaftswissenschaftler Matthias Kalkuhl erforscht, wie die Klimawende gelingen kann\"> mehr </a></span></div><div class=\"up-clear\"></div></div>,\n",
       " <div class=\"up-news-list-item\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\"><div class=\"up-news-list-item-image\"><a href=\"/de/nachrichten/detail/2021-04-06-viele-schluessel-zum-erfolg-wie-sich-das-zessko-vom-sprachen-zum-kompetenzzentrum-entwi\" title=\"Viele SchlÃ¼ssel zum Erfolg â€“ Wie sich das Zessko vom Sprachen- zum Kompetenzzentrum entwickelte\"><div class=\"news-img-wrap\"><a href=\"/de/nachrichten/detail/2021-04-06-viele-schluessel-zum-erfolg-wie-sich-das-zessko-vom-sprachen-zum-kompetenzzentrum-entwi\" title=\"Viele SchlÃ¼ssel zum Erfolg â€“ Wie sich das Zessko vom Sprachen- zum Kompetenzzentrum entwickelte\"><img alt=\"Wie sich das Zessko vom Sprachen- zum Kompetenzzentrum entwickelte | Foto: V. Kochan (Archiv)\" height=\"140\" src=\"/fileadmin/_processed_/7/7/csm_2021-03_Zessko_Foto_V-Kochan_cf829fb35d.jpg\" title=\"Wie sich das Zessko vom Sprachen- zum Kompetenzzentrum entwickelte | Foto: V. Kochan (Archiv)\" width=\"270\"/></a></div></a></div><div class=\"up-news-list-item-text\"><a href=\"/de/nachrichten/detail/2021-04-06-viele-schluessel-zum-erfolg-wie-sich-das-zessko-vom-sprachen-zum-kompetenzzentrum-entwi\" title=\"Viele SchlÃ¼ssel zum Erfolg â€“ Wie sich das Zessko vom Sprachen- zum Kompetenzzentrum entwickelte\"><h2>Viele SchlÃ¼ssel zum Erfolg â€“ Wie sich das Zessko vom Sprachen- zum Kompetenzzentrum entwickelte</h2></a><div class=\"up-news-list-published\"><time datetime=\"2021-04-06\"> 06.04.2021 </time></div><span class=\"up-news-list-text\"> Wer ihr Sekretariat am Campus Griebnitzsee betritt, darf gerne ein LÃ¤cheln aufsetzen, denn â€ždas kostet nichts und dennoch ist es das schÃ¶nste aller... </span><span class=\"up-news-list-morelink\"><a class=\"more\" href=\"/de/nachrichten/detail/2021-04-06-viele-schluessel-zum-erfolg-wie-sich-das-zessko-vom-sprachen-zum-kompetenzzentrum-entwi\" title=\"Viele SchlÃ¼ssel zum Erfolg â€“ Wie sich das Zessko vom Sprachen- zum Kompetenzzentrum entwickelte\"> mehr </a></span></div><div class=\"up-clear\"></div></div>,\n",
       " <div class=\"up-news-list-item\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\"><div class=\"up-news-list-item-image\"><a href=\"/de/nachrichten/detail/2021-03-30-im-interview-sven-dinklage-im-einsatz-als-liaison-officer-fuer-die-up-in-brasilien\" title=\"Im Interview: Sven Dinklage â€“ Im Einsatz als Liaison-Officer fÃ¼r die UP in Brasilien\"><div class=\"news-img-wrap\"><a href=\"/de/nachrichten/detail/2021-03-30-im-interview-sven-dinklage-im-einsatz-als-liaison-officer-fuer-die-up-in-brasilien\" title=\"Im Interview: Sven Dinklage â€“ Im Einsatz als Liaison-Officer fÃ¼r die UP in Brasilien\"><img alt=\"Sven Dinklage | Foto: privat\" height=\"140\" src=\"/fileadmin/_processed_/1/7/csm_2021-02_Portrait_Sven_Dinklage_copyright_privat_ae5232301d.jpg\" title=\"Sven Dinklage | Foto: privat\" width=\"270\"/></a></div></a></div><div class=\"up-news-list-item-text\"><a href=\"/de/nachrichten/detail/2021-03-30-im-interview-sven-dinklage-im-einsatz-als-liaison-officer-fuer-die-up-in-brasilien\" title=\"Im Interview: Sven Dinklage â€“ Im Einsatz als Liaison-Officer fÃ¼r die UP in Brasilien\"><h2>Im Interview: Sven Dinklage â€“ Im Einsatz als Liaison-Officer fÃ¼r die UP in Brasilien</h2></a><div class=\"up-news-list-published\"><time datetime=\"2021-03-30\"> 30.03.2021 </time></div><span class=\"up-news-list-text\"> Seit 2012 baut die UniversitÃ¤t Potsdam die wissenschaftlichen Beziehungen nach Brasilien, insbesondere zu den UniversitÃ¤ten des Bundesstaates SÃ£o... </span><span class=\"up-news-list-morelink\"><a class=\"more\" href=\"/de/nachrichten/detail/2021-03-30-im-interview-sven-dinklage-im-einsatz-als-liaison-officer-fuer-die-up-in-brasilien\" title=\"Im Interview: Sven Dinklage â€“ Im Einsatz als Liaison-Officer fÃ¼r die UP in Brasilien\"> mehr </a></span></div><div class=\"up-clear\"></div></div>,\n",
       " <div class=\"up-news-list-item\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\"><div class=\"up-news-list-item-image\"><a href=\"/de/nachrichten/detail/2021-03-29-studier-was-vernuenftiges-scivisto-gruenderin-franziska-schwarz-ueber-einen\" title=\"â€žStudier was VernÃ¼nftiges!â€œ â€“ â€žSciVisToâ€œ-GrÃ¼nderin Franziska Schwarz Ã¼ber einen ungewÃ¶hnlichen Weg in die SelbststÃ¤ndigkeit\"><div class=\"news-img-wrap\"><a href=\"/de/nachrichten/detail/2021-03-29-studier-was-vernuenftiges-scivisto-gruenderin-franziska-schwarz-ueber-einen\" title=\"â€žStudier was VernÃ¼nftiges!â€œ â€“ â€žSciVisToâ€œ-GrÃ¼nderin Franziska Schwarz Ã¼ber einen ungewÃ¶hnlichen Weg in die SelbststÃ¤ndigkeit\"><img alt=\"Franziska Schwarz visualisiert Diskussionen und Prozesse | Zeichnung: Franziska Schwarz\" height=\"140\" src=\"/fileadmin/_processed_/e/3/csm_2021-03_Zeichnung_Franziska_Schwarz_e0a9a8fcfe.jpg\" title=\"Franziska Schwarz visualisiert Diskussionen und Prozesse | Zeichnung: Franziska Schwarz\" width=\"270\"/></a></div></a></div><div class=\"up-news-list-item-text\"><a href=\"/de/nachrichten/detail/2021-03-29-studier-was-vernuenftiges-scivisto-gruenderin-franziska-schwarz-ueber-einen\" title=\"â€žStudier was VernÃ¼nftiges!â€œ â€“ â€žSciVisToâ€œ-GrÃ¼nderin Franziska Schwarz Ã¼ber einen ungewÃ¶hnlichen Weg in die SelbststÃ¤ndigkeit\"><h2>â€žStudier was VernÃ¼nftiges!â€œ â€“ â€žSciVisToâ€œ-GrÃ¼nderin Franziska Schwarz Ã¼ber einen ungewÃ¶hnlichen Weg in die SelbststÃ¤ndigkeit</h2></a><div class=\"up-news-list-published\"><time datetime=\"2021-03-29\"> 29.03.2021 </time></div><span class=\"up-news-list-text\"> HÃ¤tte mir jemand zum Abitur gesagt, dass ich einmal als zeichnende Naturwissenschaftlerin mein Geld verdienen wÃ¼rde ... So ein Unsinn! </span><span class=\"up-news-list-morelink\"><a class=\"more\" href=\"/de/nachrichten/detail/2021-03-29-studier-was-vernuenftiges-scivisto-gruenderin-franziska-schwarz-ueber-einen\" title=\"â€žStudier was VernÃ¼nftiges!â€œ â€“ â€žSciVisToâ€œ-GrÃ¼nderin Franziska Schwarz Ã¼ber einen ungewÃ¶hnlichen Weg in die SelbststÃ¤ndigkeit\"> mehr </a></span></div><div class=\"up-clear\"></div></div>,\n",
       " <div class=\"up-news-list-item\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\"><div class=\"up-news-list-item-image\"><a href=\"/de/nachrichten/detail/2021-03-25-ich-wuerde-meine-verteidigung-auch-lieber-live-durchfuehren-luise-krompholz-macht\" title=\"â€žIch wÃ¼rde meine Verteidigung auch lieber live durchfÃ¼hrenâ€œ â€“ Luise Krompholz macht ihren Abschluss an der Uni fern der Uni\"><div class=\"news-img-wrap\"><a href=\"/de/nachrichten/detail/2021-03-25-ich-wuerde-meine-verteidigung-auch-lieber-live-durchfuehren-luise-krompholz-macht\" title=\"â€žIch wÃ¼rde meine Verteidigung auch lieber live durchfÃ¼hrenâ€œ â€“ Luise Krompholz macht ihren Abschluss an der Uni fern der Uni\"><img alt=\"Luise Theresa Krompholz | Foto: privat\" height=\"140\" src=\"/fileadmin/_processed_/3/2/csm_2021-03_Luise_Krompholz_privat_f836c4ca8c.jpg\" title=\"Luise Theresa Krompholz | Foto: privat\" width=\"270\"/></a></div></a></div><div class=\"up-news-list-item-text\"><a href=\"/de/nachrichten/detail/2021-03-25-ich-wuerde-meine-verteidigung-auch-lieber-live-durchfuehren-luise-krompholz-macht\" title=\"â€žIch wÃ¼rde meine Verteidigung auch lieber live durchfÃ¼hrenâ€œ â€“ Luise Krompholz macht ihren Abschluss an der Uni fern der Uni\"><h2>â€žIch wÃ¼rde meine Verteidigung auch lieber live durchfÃ¼hrenâ€œ â€“ Luise Krompholz macht ihren Abschluss an der Uni fern der Uni</h2></a><span class=\"up-news-list-subheader\"><span class=\"up-news-list-subheader-text\"> KrisenbewÃ¤ltigung und Innovation â€“ Die digitale UniversitÃ¤t in Zeiten der Pandemie </span></span><div class=\"up-news-list-published\"><time datetime=\"2021-03-25\"> 25.03.2021 </time></div><span class=\"up-news-list-text\"> Wenn das Studium dem Ende zugeht, saugen viele noch einmal alles auf, was die Uni zu bieten hat: Auslanderfahrung, intensive Diskussionen in... </span><span class=\"up-news-list-morelink\"><a class=\"more\" href=\"/de/nachrichten/detail/2021-03-25-ich-wuerde-meine-verteidigung-auch-lieber-live-durchfuehren-luise-krompholz-macht\" title=\"â€žIch wÃ¼rde meine Verteidigung auch lieber live durchfÃ¼hrenâ€œ â€“ Luise Krompholz macht ihren Abschluss an der Uni fern der Uni\"> mehr </a></span></div><div class=\"up-clear\"></div></div>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_soup.select(css_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4d9803c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_list = list(map(lambda x: x, news_soup.select(css_element)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a03f5001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"up-news-list-item\" itemscope=\"itemscope\" itemtype=\"http://schema.org/Article\"><div class=\"up-news-list-item-image\"><a href=\"/de/nachrichten/detail/2021-04-15-studio-days-2021-digitale-studienorientierungswoche-der-staatlichen-brandenburgischen\" title=\"Studiâ€™O Days 2021 â€“ digitale Studienorientierungswoche der staatlichen brandenburgischen Hochschulen\"><div class=\"news-img-wrap\"><a href=\"/de/nachrichten/detail/2021-04-15-studio-days-2021-digitale-studienorientierungswoche-der-staatlichen-brandenburgischen\" title=\"Studiâ€™O Days 2021 â€“ digitale Studienorientierungswoche der staatlichen brandenburgischen Hochschulen\"><img alt=\"Matthias Friel, Netzwerk Studienorientierung Brandenburg\" height=\"140\" src=\"/fileadmin/_processed_/c/2/csm_2021-04_Cover_StudiODays_PM_ce48bf3905.jpg\" width=\"270\"/></a></div></a></div><div class=\"up-news-list-item-text\"><a href=\"/de/nachrichten/detail/2021-04-15-studio-days-2021-digitale-studienorientierungswoche-der-staatlichen-brandenburgischen\" title=\"Studiâ€™O Days 2021 â€“ digitale Studienorientierungswoche der staatlichen brandenburgischen Hochschulen\"><h2>Studiâ€™O Days 2021 â€“ digitale Studienorientierungswoche der staatlichen brandenburgischen Hochschulen</h2></a><div class=\"up-news-list-published\"><time datetime=\"2021-04-15\"> 15.04.2021 </time></div><span class=\"up-news-list-text\"> Das Netzwerk Studienorientierung Brandenburg lÃ¤dt vom 26. bis 30. April 2021 zur digitalen Studienorientierungswoche ein. Unter dem Motto â€žFÃ¼nf Tage,... </span><span class=\"up-news-list-morelink\"><a class=\"more\" href=\"/de/nachrichten/detail/2021-04-15-studio-days-2021-digitale-studienorientierungswoche-der-staatlichen-brandenburgischen\" title=\"Studiâ€™O Days 2021 â€“ digitale Studienorientierungswoche der staatlichen brandenburgischen Hochschulen\"> mehr </a></span></div><div class=\"up-clear\"></div></div>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22698b48",
   "metadata": {},
   "source": [
    "15. Split the list's elements into their hyperlinks (`href`) and text attributes' values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "949ac1c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/de/nachrichten/detail/2021-04-15-studio-days-2021-digitale-studienorientierungswoche-der-staatlichen-brandenburgischen'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_list[0].findChild(\"a\")['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "92241850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Tag in module bs4.element object:\n",
      "\n",
      "class Tag(PageElement)\n",
      " |  Tag(parser=None, builder=None, name=None, namespace=None, prefix=None, attrs=None, parent=None, previous=None, is_xml=None, sourceline=None, sourcepos=None, can_be_empty_element=None, cdata_list_attributes=None, preserve_whitespace_tags=None)\n",
      " |  \n",
      " |  Represents an HTML or XML tag that is part of a parse tree, along\n",
      " |  with its attributes and contents.\n",
      " |  \n",
      " |  When Beautiful Soup parses the markup <b>penguin</b>, it will\n",
      " |  create a Tag object representing the <b> tag.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Tag\n",
      " |      PageElement\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __bool__(self)\n",
      " |      A tag is non-None even if it has no contents.\n",
      " |  \n",
      " |  __call__(self, *args, **kwargs)\n",
      " |      Calling a Tag like a function is the same as calling its\n",
      " |      find_all() method. Eg. tag('a') returns a list of all the A tags\n",
      " |      found within this tag.\n",
      " |  \n",
      " |  __contains__(self, x)\n",
      " |  \n",
      " |  __copy__(self)\n",
      " |      A copy of a Tag is a new Tag, unconnected to the parse tree.\n",
      " |      Its contents are a copy of the old Tag's contents.\n",
      " |  \n",
      " |  __delitem__(self, key)\n",
      " |      Deleting tag[key] deletes all 'key' attributes for the tag.\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Returns true iff this Tag has the same name, the same attributes,\n",
      " |      and the same contents (recursively) as `other`.\n",
      " |  \n",
      " |  __getattr__(self, tag)\n",
      " |      Calling tag.subtag is the same as calling tag.find(name=\"subtag\")\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |      tag[key] returns the value of the 'key' attribute for the Tag,\n",
      " |      and throws an exception if it's not there.\n",
      " |  \n",
      " |  __hash__(self)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __init__(self, parser=None, builder=None, name=None, namespace=None, prefix=None, attrs=None, parent=None, previous=None, is_xml=None, sourceline=None, sourcepos=None, can_be_empty_element=None, cdata_list_attributes=None, preserve_whitespace_tags=None)\n",
      " |      Basic constructor.\n",
      " |      \n",
      " |      :param parser: A BeautifulSoup object.\n",
      " |      :param builder: A TreeBuilder.\n",
      " |      :param name: The name of the tag.\n",
      " |      :param namespace: The URI of this Tag's XML namespace, if any.\n",
      " |      :param prefix: The prefix for this Tag's XML namespace, if any.\n",
      " |      :param attrs: A dictionary of this Tag's attribute values.\n",
      " |      :param parent: The PageElement to use as this Tag's parent.\n",
      " |      :param previous: The PageElement that was parsed immediately before\n",
      " |          this tag.\n",
      " |      :param is_xml: If True, this is an XML tag. Otherwise, this is an\n",
      " |          HTML tag.\n",
      " |      :param sourceline: The line number where this tag was found in its\n",
      " |          source document.\n",
      " |      :param sourcepos: The character position within `sourceline` where this\n",
      " |          tag was found.\n",
      " |      :param can_be_empty_element: If True, this tag should be\n",
      " |          represented as <tag/>. If False, this tag should be represented\n",
      " |          as <tag></tag>.\n",
      " |      :param cdata_list_attributes: A list of attributes whose values should\n",
      " |          be treated as CDATA if they ever show up on this tag.\n",
      " |      :param preserve_whitespace_tags: A list of tag names whose contents\n",
      " |          should have their whitespace preserved.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Iterating over a Tag iterates over its contents.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      The length of a Tag is the length of its list of contents.\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |      Returns true iff this Tag is not identical to `other`,\n",
      " |      as defined in __eq__.\n",
      " |  \n",
      " |  __repr__ = __unicode__(self)\n",
      " |  \n",
      " |  __setitem__(self, key, value)\n",
      " |      Setting tag[key] sets the value of the 'key' attribute for the\n",
      " |      tag.\n",
      " |  \n",
      " |  __str__ = __unicode__(self)\n",
      " |  \n",
      " |  __unicode__(self)\n",
      " |      Renders this PageElement as a Unicode string.\n",
      " |  \n",
      " |  childGenerator(self)\n",
      " |      Deprecated generator.\n",
      " |  \n",
      " |  clear(self, decompose=False)\n",
      " |      Wipe out all children of this PageElement by calling extract()\n",
      " |         on them.\n",
      " |      \n",
      " |      :param decompose: If this is True, decompose() (a more\n",
      " |          destructive method) will be called instead of extract().\n",
      " |  \n",
      " |  decode(self, indent_level=None, eventual_encoding='utf-8', formatter='minimal')\n",
      " |      Render a Unicode representation of this PageElement and its\n",
      " |      contents.\n",
      " |      \n",
      " |      :param indent_level: Each line of the rendering will be\n",
      " |           indented this many spaces. Used internally in\n",
      " |           recursive calls while pretty-printing.\n",
      " |      :param eventual_encoding: The tag is destined to be\n",
      " |          encoded into this encoding. This method is _not_\n",
      " |          responsible for performing that encoding. This information\n",
      " |          is passed in so that it can be substituted in if the\n",
      " |          document contains a <META> tag that mentions the document's\n",
      " |          encoding.\n",
      " |      :param formatter: A Formatter object, or a string naming one of\n",
      " |          the standard formatters.\n",
      " |  \n",
      " |  decode_contents(self, indent_level=None, eventual_encoding='utf-8', formatter='minimal')\n",
      " |      Renders the contents of this tag as a Unicode string.\n",
      " |      \n",
      " |      :param indent_level: Each line of the rendering will be\n",
      " |         indented this many spaces. Used internally in\n",
      " |         recursive calls while pretty-printing.\n",
      " |      \n",
      " |      :param eventual_encoding: The tag is destined to be\n",
      " |         encoded into this encoding. decode_contents() is _not_\n",
      " |         responsible for performing that encoding. This information\n",
      " |         is passed in so that it can be substituted in if the\n",
      " |         document contains a <META> tag that mentions the document's\n",
      " |         encoding.\n",
      " |      \n",
      " |      :param formatter: A Formatter object, or a string naming one of\n",
      " |          the standard Formatters.\n",
      " |  \n",
      " |  decompose(self)\n",
      " |      Recursively destroys this PageElement and its children.\n",
      " |      \n",
      " |      This element will be removed from the tree and wiped out; so\n",
      " |      will everything beneath it.\n",
      " |      \n",
      " |      The behavior of a decomposed PageElement is undefined and you\n",
      " |      should never use one for anything, but if you need to _check_\n",
      " |      whether an element has been decomposed, you can use the\n",
      " |      `decomposed` property.\n",
      " |  \n",
      " |  encode(self, encoding='utf-8', indent_level=None, formatter='minimal', errors='xmlcharrefreplace')\n",
      " |      Render a bytestring representation of this PageElement and its\n",
      " |      contents.\n",
      " |      \n",
      " |      :param encoding: The destination encoding.\n",
      " |      :param indent_level: Each line of the rendering will be\n",
      " |          indented this many spaces. Used internally in\n",
      " |          recursive calls while pretty-printing.\n",
      " |      :param formatter: A Formatter object, or a string naming one of\n",
      " |          the standard formatters.\n",
      " |      :param errors: An error handling strategy such as\n",
      " |          'xmlcharrefreplace'. This value is passed along into\n",
      " |          encode() and its value should be one of the constants\n",
      " |          defined by Python.\n",
      " |      :return: A bytestring.\n",
      " |  \n",
      " |  encode_contents(self, indent_level=None, encoding='utf-8', formatter='minimal')\n",
      " |      Renders the contents of this PageElement as a bytestring.\n",
      " |      \n",
      " |      :param indent_level: Each line of the rendering will be\n",
      " |         indented this many spaces. Used internally in\n",
      " |         recursive calls while pretty-printing.\n",
      " |      \n",
      " |      :param eventual_encoding: The bytestring will be in this encoding.\n",
      " |      \n",
      " |      :param formatter: A Formatter object, or a string naming one of\n",
      " |          the standard Formatters.\n",
      " |      \n",
      " |      :return: A bytestring.\n",
      " |  \n",
      " |  find(self, name=None, attrs={}, recursive=True, text=None, **kwargs)\n",
      " |      Look in the children of this PageElement and find the first\n",
      " |      PageElement that matches the given criteria.\n",
      " |      \n",
      " |      All find_* methods take a common set of arguments. See the online\n",
      " |      documentation for detailed explanations.\n",
      " |      \n",
      " |      :param name: A filter on tag name.\n",
      " |      :param attrs: A dictionary of filters on attribute values.\n",
      " |      :param recursive: If this is True, find() will perform a\n",
      " |          recursive search of this PageElement's children. Otherwise,\n",
      " |          only the direct children will be considered.\n",
      " |      :param limit: Stop looking after finding this many results.\n",
      " |      :kwargs: A dictionary of filters on attribute values.\n",
      " |      :return: A PageElement.\n",
      " |      :rtype: bs4.element.Tag | bs4.element.NavigableString\n",
      " |  \n",
      " |  findAll = find_all(self, name=None, attrs={}, recursive=True, text=None, limit=None, **kwargs)\n",
      " |  \n",
      " |  findChild = find(self, name=None, attrs={}, recursive=True, text=None, **kwargs)\n",
      " |  \n",
      " |  findChildren = find_all(self, name=None, attrs={}, recursive=True, text=None, limit=None, **kwargs)\n",
      " |  \n",
      " |  find_all(self, name=None, attrs={}, recursive=True, text=None, limit=None, **kwargs)\n",
      " |      Look in the children of this PageElement and find all\n",
      " |      PageElements that match the given criteria.\n",
      " |      \n",
      " |      All find_* methods take a common set of arguments. See the online\n",
      " |      documentation for detailed explanations.\n",
      " |      \n",
      " |      :param name: A filter on tag name.\n",
      " |      :param attrs: A dictionary of filters on attribute values.\n",
      " |      :param recursive: If this is True, find_all() will perform a\n",
      " |          recursive search of this PageElement's children. Otherwise,\n",
      " |          only the direct children will be considered.\n",
      " |      :param limit: Stop looking after finding this many results.\n",
      " |      :kwargs: A dictionary of filters on attribute values.\n",
      " |      :return: A ResultSet of PageElements.\n",
      " |      :rtype: bs4.element.ResultSet\n",
      " |  \n",
      " |  get(self, key, default=None)\n",
      " |      Returns the value of the 'key' attribute for the tag, or\n",
      " |      the value given for 'default' if it doesn't have that\n",
      " |      attribute.\n",
      " |  \n",
      " |  getText = get_text(self, separator='', strip=False, types=(<class 'bs4.element.NavigableString'>, <class 'bs4.element.CData'>))\n",
      " |  \n",
      " |  get_attribute_list(self, key, default=None)\n",
      " |      The same as get(), but always returns a list.\n",
      " |      \n",
      " |      :param key: The attribute to look for.\n",
      " |      :param default: Use this value if the attribute is not present\n",
      " |          on this PageElement.\n",
      " |      :return: A list of values, probably containing only a single\n",
      " |          value.\n",
      " |  \n",
      " |  get_text(self, separator='', strip=False, types=(<class 'bs4.element.NavigableString'>, <class 'bs4.element.CData'>))\n",
      " |      Get all child strings, concatenated using the given separator.\n",
      " |      \n",
      " |      :param separator: Strings will be concatenated using this separator.\n",
      " |      \n",
      " |      :param strip: If True, strings will be stripped before being\n",
      " |          concatenated.\n",
      " |      \n",
      " |      :types: A tuple of NavigableString subclasses. Any strings of\n",
      " |          a subclass not found in this list will be ignored. By\n",
      " |          default, this means only NavigableString and CData objects\n",
      " |          will be considered. So no comments, processing instructions,\n",
      " |          stylesheets, etc.\n",
      " |      \n",
      " |      :return: A string.\n",
      " |  \n",
      " |  has_attr(self, key)\n",
      " |      Does this PageElement have an attribute with the given name?\n",
      " |  \n",
      " |  has_key(self, key)\n",
      " |      Deprecated method. This was kind of misleading because has_key()\n",
      " |      (attributes) was different from __in__ (contents).\n",
      " |      \n",
      " |      has_key() is gone in Python 3, anyway.\n",
      " |  \n",
      " |  index(self, element)\n",
      " |      Find the index of a child by identity, not value.\n",
      " |      \n",
      " |      Avoids issues with tag.contents.index(element) getting the\n",
      " |      index of equal elements.\n",
      " |      \n",
      " |      :param element: Look for this PageElement in `self.contents`.\n",
      " |  \n",
      " |  prettify(self, encoding=None, formatter='minimal')\n",
      " |      Pretty-print this PageElement as a string.\n",
      " |      \n",
      " |      :param encoding: The eventual encoding of the string. If this is None,\n",
      " |          a Unicode string will be returned.\n",
      " |      :param formatter: A Formatter object, or a string naming one of\n",
      " |          the standard formatters.\n",
      " |      :return: A Unicode string (if encoding==None) or a bytestring \n",
      " |          (otherwise).\n",
      " |  \n",
      " |  recursiveChildGenerator(self)\n",
      " |      Deprecated generator.\n",
      " |  \n",
      " |  renderContents(self, encoding='utf-8', prettyPrint=False, indentLevel=0)\n",
      " |      Deprecated method for BS3 compatibility.\n",
      " |  \n",
      " |  select(self, selector, namespaces=None, limit=None, **kwargs)\n",
      " |      Perform a CSS selection operation on the current element.\n",
      " |      \n",
      " |      This uses the SoupSieve library.\n",
      " |      \n",
      " |      :param selector: A string containing a CSS selector.\n",
      " |      \n",
      " |      :param namespaces: A dictionary mapping namespace prefixes\n",
      " |         used in the CSS selector to namespace URIs. By default,\n",
      " |         Beautiful Soup will use the prefixes it encountered while\n",
      " |         parsing the document.\n",
      " |      \n",
      " |      :param limit: After finding this number of results, stop looking.\n",
      " |      \n",
      " |      :param kwargs: Keyword arguments to be passed into SoupSieve's \n",
      " |         soupsieve.select() method.\n",
      " |      \n",
      " |      :return: A ResultSet of Tags.\n",
      " |      :rtype: bs4.element.ResultSet\n",
      " |  \n",
      " |  select_one(self, selector, namespaces=None, **kwargs)\n",
      " |      Perform a CSS selection operation on the current element.\n",
      " |      \n",
      " |      :param selector: A CSS selector.\n",
      " |      \n",
      " |      :param namespaces: A dictionary mapping namespace prefixes\n",
      " |         used in the CSS selector to namespace URIs. By default,\n",
      " |         Beautiful Soup will use the prefixes it encountered while\n",
      " |         parsing the document.\n",
      " |      \n",
      " |      :param kwargs: Keyword arguments to be passed into SoupSieve's \n",
      " |         soupsieve.select() method.\n",
      " |      \n",
      " |      :return: A Tag.\n",
      " |      :rtype: bs4.element.Tag\n",
      " |  \n",
      " |  smooth(self)\n",
      " |      Smooth out this element's children by consolidating consecutive\n",
      " |      strings.\n",
      " |      \n",
      " |      This makes pretty-printed output look more natural following a\n",
      " |      lot of operations that modified the tree.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  children\n",
      " |      Iterate over all direct children of this PageElement.\n",
      " |      \n",
      " |      :yield: A sequence of PageElements.\n",
      " |  \n",
      " |  descendants\n",
      " |      Iterate over all children of this PageElement in a\n",
      " |      breadth-first sequence.\n",
      " |      \n",
      " |      :yield: A sequence of PageElements.\n",
      " |  \n",
      " |  isSelfClosing\n",
      " |      Is this tag an empty-element tag? (aka a self-closing tag)\n",
      " |      \n",
      " |      A tag that has contents is never an empty-element tag.\n",
      " |      \n",
      " |      A tag that has no contents may or may not be an empty-element\n",
      " |      tag. It depends on the builder used to create the tag. If the\n",
      " |      builder has a designated list of empty-element tags, then only\n",
      " |      a tag whose name shows up in that list is considered an\n",
      " |      empty-element tag.\n",
      " |      \n",
      " |      If the builder has no designated list of empty-element tags,\n",
      " |      then any tag with no contents is an empty-element tag.\n",
      " |  \n",
      " |  is_empty_element\n",
      " |      Is this tag an empty-element tag? (aka a self-closing tag)\n",
      " |      \n",
      " |      A tag that has contents is never an empty-element tag.\n",
      " |      \n",
      " |      A tag that has no contents may or may not be an empty-element\n",
      " |      tag. It depends on the builder used to create the tag. If the\n",
      " |      builder has a designated list of empty-element tags, then only\n",
      " |      a tag whose name shows up in that list is considered an\n",
      " |      empty-element tag.\n",
      " |      \n",
      " |      If the builder has no designated list of empty-element tags,\n",
      " |      then any tag with no contents is an empty-element tag.\n",
      " |  \n",
      " |  strings\n",
      " |      Yield all strings of certain classes, possibly stripping them.\n",
      " |      \n",
      " |      :param strip: If True, all strings will be stripped before being\n",
      " |          yielded.\n",
      " |      \n",
      " |      :types: A tuple of NavigableString subclasses. Any strings of\n",
      " |          a subclass not found in this list will be ignored. By\n",
      " |          default, this means only NavigableString and CData objects\n",
      " |          will be considered. So no comments, processing instructions,\n",
      " |          etc.\n",
      " |      \n",
      " |      :yield: A sequence of strings.\n",
      " |  \n",
      " |  stripped_strings\n",
      " |      Yield all strings in the document, stripping them first.\n",
      " |      \n",
      " |      :yield: A sequence of stripped strings.\n",
      " |  \n",
      " |  text\n",
      " |      Get all child strings, concatenated using the given separator.\n",
      " |      \n",
      " |      :param separator: Strings will be concatenated using this separator.\n",
      " |      \n",
      " |      :param strip: If True, strings will be stripped before being\n",
      " |          concatenated.\n",
      " |      \n",
      " |      :types: A tuple of NavigableString subclasses. Any strings of\n",
      " |          a subclass not found in this list will be ignored. By\n",
      " |          default, this means only NavigableString and CData objects\n",
      " |          will be considered. So no comments, processing instructions,\n",
      " |          stylesheets, etc.\n",
      " |      \n",
      " |      :return: A string.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  parserClass\n",
      " |  \n",
      " |  string\n",
      " |      Convenience property to get the single string within this\n",
      " |      PageElement.\n",
      " |      \n",
      " |      TODO It might make sense to have NavigableString.string return\n",
      " |      itself.\n",
      " |      \n",
      " |      :return: If this element has a single string child, return\n",
      " |       value is that string. If this element has one child tag,\n",
      " |       return value is the 'string' attribute of the child tag,\n",
      " |       recursively. If this element is itself a string, has no\n",
      " |       children, or has more than one child, return value is None.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from PageElement:\n",
      " |  \n",
      " |  append(self, tag)\n",
      " |      Appends the given PageElement to the contents of this one.\n",
      " |      \n",
      " |      :param tag: A PageElement.\n",
      " |  \n",
      " |  extend(self, tags)\n",
      " |      Appends the given PageElements to this one's contents.\n",
      " |      \n",
      " |      :param tags: A list of PageElements.\n",
      " |  \n",
      " |  extract(self, _self_index=None)\n",
      " |      Destructively rips this element out of the tree.\n",
      " |      \n",
      " |      :param _self_index: The location of this element in its parent's\n",
      " |         .contents, if known. Passing this in allows for a performance\n",
      " |         optimization.\n",
      " |      \n",
      " |      :return: `self`, no longer part of the tree.\n",
      " |  \n",
      " |  fetchNextSiblings = find_next_siblings(self, name=None, attrs={}, text=None, limit=None, **kwargs)\n",
      " |  \n",
      " |  fetchParents = find_parents(self, name=None, attrs={}, limit=None, **kwargs)\n",
      " |  \n",
      " |  fetchPrevious = find_all_previous(self, name=None, attrs={}, text=None, limit=None, **kwargs)\n",
      " |  \n",
      " |  fetchPreviousSiblings = find_previous_siblings(self, name=None, attrs={}, text=None, limit=None, **kwargs)\n",
      " |  \n",
      " |  findAllNext = find_all_next(self, name=None, attrs={}, text=None, limit=None, **kwargs)\n",
      " |  \n",
      " |  findAllPrevious = find_all_previous(self, name=None, attrs={}, text=None, limit=None, **kwargs)\n",
      " |  \n",
      " |  findNext = find_next(self, name=None, attrs={}, text=None, **kwargs)\n",
      " |  \n",
      " |  findNextSibling = find_next_sibling(self, name=None, attrs={}, text=None, **kwargs)\n",
      " |  \n",
      " |  findNextSiblings = find_next_siblings(self, name=None, attrs={}, text=None, limit=None, **kwargs)\n",
      " |  \n",
      " |  findParent = find_parent(self, name=None, attrs={}, **kwargs)\n",
      " |  \n",
      " |  findParents = find_parents(self, name=None, attrs={}, limit=None, **kwargs)\n",
      " |  \n",
      " |  findPrevious = find_previous(self, name=None, attrs={}, text=None, **kwargs)\n",
      " |  \n",
      " |  findPreviousSibling = find_previous_sibling(self, name=None, attrs={}, text=None, **kwargs)\n",
      " |  \n",
      " |  findPreviousSiblings = find_previous_siblings(self, name=None, attrs={}, text=None, limit=None, **kwargs)\n",
      " |  \n",
      " |  find_all_next(self, name=None, attrs={}, text=None, limit=None, **kwargs)\n",
      " |      Find all PageElements that match the given criteria and appear\n",
      " |      later in the document than this PageElement.\n",
      " |      \n",
      " |      All find_* methods take a common set of arguments. See the online\n",
      " |      documentation for detailed explanations.\n",
      " |      \n",
      " |      :param name: A filter on tag name.\n",
      " |      :param attrs: A dictionary of filters on attribute values.\n",
      " |      :param text: A filter for a NavigableString with specific text.\n",
      " |      :param limit: Stop looking after finding this many results.\n",
      " |      :kwargs: A dictionary of filters on attribute values.\n",
      " |      :return: A ResultSet containing PageElements.\n",
      " |  \n",
      " |  find_all_previous(self, name=None, attrs={}, text=None, limit=None, **kwargs)\n",
      " |      Look backwards in the document from this PageElement and find all\n",
      " |      PageElements that match the given criteria.\n",
      " |      \n",
      " |      All find_* methods take a common set of arguments. See the online\n",
      " |      documentation for detailed explanations.\n",
      " |      \n",
      " |      :param name: A filter on tag name.\n",
      " |      :param attrs: A dictionary of filters on attribute values.\n",
      " |      :param text: A filter for a NavigableString with specific text.\n",
      " |      :param limit: Stop looking after finding this many results.\n",
      " |      :kwargs: A dictionary of filters on attribute values.\n",
      " |      :return: A ResultSet of PageElements.\n",
      " |      :rtype: bs4.element.ResultSet\n",
      " |  \n",
      " |  find_next(self, name=None, attrs={}, text=None, **kwargs)\n",
      " |      Find the first PageElement that matches the given criteria and\n",
      " |      appears later in the document than this PageElement.\n",
      " |      \n",
      " |      All find_* methods take a common set of arguments. See the online\n",
      " |      documentation for detailed explanations.\n",
      " |      \n",
      " |      :param name: A filter on tag name.\n",
      " |      :param attrs: A dictionary of filters on attribute values.\n",
      " |      :param text: A filter for a NavigableString with specific text.\n",
      " |      :kwargs: A dictionary of filters on attribute values.\n",
      " |      :return: A PageElement.\n",
      " |      :rtype: bs4.element.Tag | bs4.element.NavigableString\n",
      " |  \n",
      " |  find_next_sibling(self, name=None, attrs={}, text=None, **kwargs)\n",
      " |      Find the closest sibling to this PageElement that matches the\n",
      " |      given criteria and appears later in the document.\n",
      " |      \n",
      " |      All find_* methods take a common set of arguments. See the\n",
      " |      online documentation for detailed explanations.\n",
      " |      \n",
      " |      :param name: A filter on tag name.\n",
      " |      :param attrs: A dictionary of filters on attribute values.\n",
      " |      :param text: A filter for a NavigableString with specific text.\n",
      " |      :kwargs: A dictionary of filters on attribute values.\n",
      " |      :return: A PageElement.\n",
      " |      :rtype: bs4.element.Tag | bs4.element.NavigableString\n",
      " |  \n",
      " |  find_next_siblings(self, name=None, attrs={}, text=None, limit=None, **kwargs)\n",
      " |      Find all siblings of this PageElement that match the given criteria\n",
      " |      and appear later in the document.\n",
      " |      \n",
      " |      All find_* methods take a common set of arguments. See the online\n",
      " |      documentation for detailed explanations.\n",
      " |      \n",
      " |      :param name: A filter on tag name.\n",
      " |      :param attrs: A dictionary of filters on attribute values.\n",
      " |      :param text: A filter for a NavigableString with specific text.\n",
      " |      :param limit: Stop looking after finding this many results.\n",
      " |      :kwargs: A dictionary of filters on attribute values.\n",
      " |      :return: A ResultSet of PageElements.\n",
      " |      :rtype: bs4.element.ResultSet\n",
      " |  \n",
      " |  find_parent(self, name=None, attrs={}, **kwargs)\n",
      " |      Find the closest parent of this PageElement that matches the given\n",
      " |      criteria.\n",
      " |      \n",
      " |      All find_* methods take a common set of arguments. See the online\n",
      " |      documentation for detailed explanations.\n",
      " |      \n",
      " |      :param name: A filter on tag name.\n",
      " |      :param attrs: A dictionary of filters on attribute values.\n",
      " |      :kwargs: A dictionary of filters on attribute values.\n",
      " |      \n",
      " |      :return: A PageElement.\n",
      " |      :rtype: bs4.element.Tag | bs4.element.NavigableString\n",
      " |  \n",
      " |  find_parents(self, name=None, attrs={}, limit=None, **kwargs)\n",
      " |      Find all parents of this PageElement that match the given criteria.\n",
      " |      \n",
      " |      All find_* methods take a common set of arguments. See the online\n",
      " |      documentation for detailed explanations.\n",
      " |      \n",
      " |      :param name: A filter on tag name.\n",
      " |      :param attrs: A dictionary of filters on attribute values.\n",
      " |      :param limit: Stop looking after finding this many results.\n",
      " |      :kwargs: A dictionary of filters on attribute values.\n",
      " |      \n",
      " |      :return: A PageElement.\n",
      " |      :rtype: bs4.element.Tag | bs4.element.NavigableString\n",
      " |  \n",
      " |  find_previous(self, name=None, attrs={}, text=None, **kwargs)\n",
      " |      Look backwards in the document from this PageElement and find the\n",
      " |      first PageElement that matches the given criteria.\n",
      " |      \n",
      " |      All find_* methods take a common set of arguments. See the online\n",
      " |      documentation for detailed explanations.\n",
      " |      \n",
      " |      :param name: A filter on tag name.\n",
      " |      :param attrs: A dictionary of filters on attribute values.\n",
      " |      :param text: A filter for a NavigableString with specific text.\n",
      " |      :kwargs: A dictionary of filters on attribute values.\n",
      " |      :return: A PageElement.\n",
      " |      :rtype: bs4.element.Tag | bs4.element.NavigableString\n",
      " |  \n",
      " |  find_previous_sibling(self, name=None, attrs={}, text=None, **kwargs)\n",
      " |      Returns the closest sibling to this PageElement that matches the\n",
      " |      given criteria and appears earlier in the document.\n",
      " |      \n",
      " |      All find_* methods take a common set of arguments. See the online\n",
      " |      documentation for detailed explanations.\n",
      " |      \n",
      " |      :param name: A filter on tag name.\n",
      " |      :param attrs: A dictionary of filters on attribute values.\n",
      " |      :param text: A filter for a NavigableString with specific text.\n",
      " |      :kwargs: A dictionary of filters on attribute values.\n",
      " |      :return: A PageElement.\n",
      " |      :rtype: bs4.element.Tag | bs4.element.NavigableString\n",
      " |  \n",
      " |  find_previous_siblings(self, name=None, attrs={}, text=None, limit=None, **kwargs)\n",
      " |      Returns all siblings to this PageElement that match the\n",
      " |      given criteria and appear earlier in the document.\n",
      " |      \n",
      " |      All find_* methods take a common set of arguments. See the online\n",
      " |      documentation for detailed explanations.\n",
      " |      \n",
      " |      :param name: A filter on tag name.\n",
      " |      :param attrs: A dictionary of filters on attribute values.\n",
      " |      :param text: A filter for a NavigableString with specific text.\n",
      " |      :param limit: Stop looking after finding this many results.\n",
      " |      :kwargs: A dictionary of filters on attribute values.\n",
      " |      :return: A ResultSet of PageElements.\n",
      " |      :rtype: bs4.element.ResultSet\n",
      " |  \n",
      " |  format_string(self, s, formatter)\n",
      " |      Format the given string using the given formatter.\n",
      " |      \n",
      " |      :param s: A string.\n",
      " |      :param formatter: A Formatter object, or a string naming one of the standard formatters.\n",
      " |  \n",
      " |  formatter_for_name(self, formatter)\n",
      " |      Look up or create a Formatter for the given identifier,\n",
      " |      if necessary.\n",
      " |      \n",
      " |      :param formatter: Can be a Formatter object (used as-is), a\n",
      " |          function (used as the entity substitution hook for an\n",
      " |          XMLFormatter or HTMLFormatter), or a string (used to look\n",
      " |          up an XMLFormatter or HTMLFormatter in the appropriate\n",
      " |          registry.\n",
      " |  \n",
      " |  insert(self, position, new_child)\n",
      " |      Insert a new PageElement in the list of this PageElement's children.\n",
      " |      \n",
      " |      This works the same way as `list.insert`.\n",
      " |      \n",
      " |      :param position: The numeric position that should be occupied\n",
      " |         in `self.children` by the new PageElement. \n",
      " |      :param new_child: A PageElement.\n",
      " |  \n",
      " |  insert_after(self, *args)\n",
      " |      Makes the given element(s) the immediate successor of this one.\n",
      " |      \n",
      " |      The elements will have the same parent, and the given elements\n",
      " |      will be immediately after this one.\n",
      " |      \n",
      " |      :param args: One or more PageElements.\n",
      " |  \n",
      " |  insert_before(self, *args)\n",
      " |      Makes the given element(s) the immediate predecessor of this one.\n",
      " |      \n",
      " |      All the elements will have the same parent, and the given elements\n",
      " |      will be immediately before this one.\n",
      " |      \n",
      " |      :param args: One or more PageElements.\n",
      " |  \n",
      " |  nextGenerator(self)\n",
      " |      # Old non-property versions of the generators, for backwards\n",
      " |      # compatibility with BS3.\n",
      " |  \n",
      " |  nextSiblingGenerator(self)\n",
      " |  \n",
      " |  parentGenerator(self)\n",
      " |  \n",
      " |  previousGenerator(self)\n",
      " |  \n",
      " |  previousSiblingGenerator(self)\n",
      " |  \n",
      " |  replaceWith = replace_with(self, replace_with)\n",
      " |  \n",
      " |  replaceWithChildren = unwrap(self)\n",
      " |  \n",
      " |  replace_with(self, replace_with)\n",
      " |      Replace this PageElement with another one, keeping the rest of the\n",
      " |      tree the same.\n",
      " |      \n",
      " |      :param replace_with: A PageElement.\n",
      " |      :return: `self`, no longer part of the tree.\n",
      " |  \n",
      " |  replace_with_children = unwrap(self)\n",
      " |  \n",
      " |  setup(self, parent=None, previous_element=None, next_element=None, previous_sibling=None, next_sibling=None)\n",
      " |      Sets up the initial relations between this element and\n",
      " |      other elements.\n",
      " |      \n",
      " |      :param parent: The parent of this element.\n",
      " |      \n",
      " |      :param previous_element: The element parsed immediately before\n",
      " |          this one.\n",
      " |      \n",
      " |      :param next_element: The element parsed immediately before\n",
      " |          this one.\n",
      " |      \n",
      " |      :param previous_sibling: The most recently encountered element\n",
      " |          on the same level of the parse tree as this one.\n",
      " |      \n",
      " |      :param previous_sibling: The next element to be encountered\n",
      " |          on the same level of the parse tree as this one.\n",
      " |  \n",
      " |  unwrap(self)\n",
      " |      Replace this PageElement with its contents.\n",
      " |      \n",
      " |      :return: `self`, no longer part of the tree.\n",
      " |  \n",
      " |  wrap(self, wrap_inside)\n",
      " |      Wrap this PageElement inside another one.\n",
      " |      \n",
      " |      :param wrap_inside: A PageElement.\n",
      " |      :return: `wrap_inside`, occupying the position in the tree that used\n",
      " |         to be occupied by `self`, and with `self` inside it.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from PageElement:\n",
      " |  \n",
      " |  decomposed\n",
      " |      Check whether a PageElement has been decomposed.\n",
      " |      \n",
      " |      :rtype: bool\n",
      " |  \n",
      " |  next\n",
      " |      The PageElement, if any, that was parsed just after this one.\n",
      " |      \n",
      " |      :return: A PageElement.\n",
      " |      :rtype: bs4.element.Tag | bs4.element.NavigableString\n",
      " |  \n",
      " |  next_elements\n",
      " |      All PageElements that were parsed after this one.\n",
      " |      \n",
      " |      :yield: A sequence of PageElements.\n",
      " |  \n",
      " |  next_siblings\n",
      " |      All PageElements that are siblings of this one but were parsed\n",
      " |      later.\n",
      " |      \n",
      " |      :yield: A sequence of PageElements.\n",
      " |  \n",
      " |  parents\n",
      " |      All PageElements that are parents of this PageElement.\n",
      " |      \n",
      " |      :yield: A sequence of PageElements.\n",
      " |  \n",
      " |  previous\n",
      " |      The PageElement, if any, that was parsed just before this one.\n",
      " |      \n",
      " |      :return: A PageElement.\n",
      " |      :rtype: bs4.element.Tag | bs4.element.NavigableString\n",
      " |  \n",
      " |  previous_elements\n",
      " |      All PageElements that were parsed before this one.\n",
      " |      \n",
      " |      :yield: A sequence of PageElements.\n",
      " |  \n",
      " |  previous_siblings\n",
      " |      All PageElements that are siblings of this one but were parsed\n",
      " |      earlier.\n",
      " |      \n",
      " |      :yield: A sequence of PageElements.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from PageElement:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  nextSibling\n",
      " |  \n",
      " |  previousSibling\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(news_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3680ed91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Studiâ€™O Days 2021 â€“ digitale Studienorientierungswoche der staatlichen brandenburgischen Hochschulen'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_list[0].findChild(\"a\")['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "54b54191",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_list = []\n",
    "title_list = []\n",
    "\n",
    "for link_num in range(len(news_list)):\n",
    "    \n",
    "    sub_link = news_list[link_num].findChild(\"a\")['href']\n",
    "    sub_title = news_list[link_num].findChild(\"a\")['title']\n",
    "    \n",
    "    if type(sub_link) is str and 'www' not in sub_link:\n",
    "        \n",
    "        link_list.append('https://www.uni-potsdam.de' + sub_link)\n",
    "        title_list.append(sub_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9f9d0c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.uni-potsdam.de/de/nachrichten/detail/2021-04-15-studio-days-2021-digitale-studienorientierungswoche-der-staatlichen-brandenburgischen',\n",
       " 'https://www.uni-potsdam.de/de/nachrichten/detail/2021-04-15-hoppla-jetzt-kommt-koppla-die-revolution-fuers-handwerk',\n",
       " 'https://www.uni-potsdam.de/de/nachrichten/detail/2021-04-13-science-fiction-experimentelle-kooperation-von-germanistik-und-food4future',\n",
       " 'https://www.uni-potsdam.de/de/nachrichten/detail/2021-04-13-wir-waren-exotisch-der-linguist-gisbert-fanselow-und-der-psychologe-reinhold-klie',\n",
       " 'https://www.uni-potsdam.de/de/nachrichten/detail/2021-04-12-eine-bruecke-in-den-arbeitsmarkt-warum-betriebswirtin-kristina-nistor-noch-einmal-zur-uni-g',\n",
       " 'https://www.uni-potsdam.de/de/nachrichten/detail/2021-04-08-die-klima-uhr-tickt-der-wirtschaftswissenschaftler-matthias-kalkuhl-erforscht-wie-die-k',\n",
       " 'https://www.uni-potsdam.de/de/nachrichten/detail/2021-04-06-viele-schluessel-zum-erfolg-wie-sich-das-zessko-vom-sprachen-zum-kompetenzzentrum-entwi',\n",
       " 'https://www.uni-potsdam.de/de/nachrichten/detail/2021-03-30-im-interview-sven-dinklage-im-einsatz-als-liaison-officer-fuer-die-up-in-brasilien',\n",
       " 'https://www.uni-potsdam.de/de/nachrichten/detail/2021-03-29-studier-was-vernuenftiges-scivisto-gruenderin-franziska-schwarz-ueber-einen',\n",
       " 'https://www.uni-potsdam.de/de/nachrichten/detail/2021-03-25-ich-wuerde-meine-verteidigung-auch-lieber-live-durchfuehren-luise-krompholz-macht']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cc854f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Studiâ€™O Days 2021 â€“ digitale Studienorientierungswoche der staatlichen brandenburgischen Hochschulen',\n",
       " 'Hoppla! Jetzt kommt Koppla! â€“ Die Revolution fÃ¼rs Handwerk',\n",
       " 'Science / Fiction â€“ Experimentelle Kooperation von Germanistik und food4future',\n",
       " 'â€žWir waren exotisch!â€œ â€“ Der Linguist Gisbert Fanselow und der Psychologe Reinhold Kliegl im GesprÃ¤ch Ã¼ber lÃ¶chrige DÃ¤cher, schwierige AnfÃ¤nge und die richtigen Forschungsfragen',\n",
       " 'Eine BrÃ¼cke in den Arbeitsmarkt: Warum Betriebswirtin Kristina Nistor noch einmal zur Uni ging',\n",
       " 'Die Klima-Uhr tickt â€“ Der Wirtschaftswissenschaftler Matthias Kalkuhl erforscht, wie die Klimawende gelingen kann',\n",
       " 'Viele SchlÃ¼ssel zum Erfolg â€“ Wie sich das Zessko vom Sprachen- zum Kompetenzzentrum entwickelte',\n",
       " 'Im Interview: Sven Dinklage â€“ Im Einsatz als Liaison-Officer fÃ¼r die UP in Brasilien',\n",
       " 'â€žStudier was VernÃ¼nftiges!â€œ â€“ â€žSciVisToâ€œ-GrÃ¼nderin Franziska Schwarz Ã¼ber einen ungewÃ¶hnlichen Weg in die SelbststÃ¤ndigkeit',\n",
       " 'â€žIch wÃ¼rde meine Verteidigung auch lieber live durchfÃ¼hrenâ€œ â€“ Luise Krompholz macht ihren Abschluss an der Uni fern der Uni']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "caa44ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lot = list(zip(title_list, link_list))\n",
    "news_dict = dict(lot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f4eb2b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Studiâ€™O Days 2021 â€“ digitale Studienorientierungswoche der staatlichen brandenburgischen Hochschulen': 'https://www.uni-potsdam.de/de/nachrichten/detail/2021-04-15-studio-days-2021-digitale-studienorientierungswoche-der-staatlichen-brandenburgischen',\n",
       " 'Hoppla! Jetzt kommt Koppla! â€“ Die Revolution fÃ¼rs Handwerk': 'https://www.uni-potsdam.de/de/nachrichten/detail/2021-04-15-hoppla-jetzt-kommt-koppla-die-revolution-fuers-handwerk',\n",
       " 'Science / Fiction â€“ Experimentelle Kooperation von Germanistik und food4future': 'https://www.uni-potsdam.de/de/nachrichten/detail/2021-04-13-science-fiction-experimentelle-kooperation-von-germanistik-und-food4future',\n",
       " 'â€žWir waren exotisch!â€œ â€“ Der Linguist Gisbert Fanselow und der Psychologe Reinhold Kliegl im GesprÃ¤ch Ã¼ber lÃ¶chrige DÃ¤cher, schwierige AnfÃ¤nge und die richtigen Forschungsfragen': 'https://www.uni-potsdam.de/de/nachrichten/detail/2021-04-13-wir-waren-exotisch-der-linguist-gisbert-fanselow-und-der-psychologe-reinhold-klie',\n",
       " 'Eine BrÃ¼cke in den Arbeitsmarkt: Warum Betriebswirtin Kristina Nistor noch einmal zur Uni ging': 'https://www.uni-potsdam.de/de/nachrichten/detail/2021-04-12-eine-bruecke-in-den-arbeitsmarkt-warum-betriebswirtin-kristina-nistor-noch-einmal-zur-uni-g',\n",
       " 'Die Klima-Uhr tickt â€“ Der Wirtschaftswissenschaftler Matthias Kalkuhl erforscht, wie die Klimawende gelingen kann': 'https://www.uni-potsdam.de/de/nachrichten/detail/2021-04-08-die-klima-uhr-tickt-der-wirtschaftswissenschaftler-matthias-kalkuhl-erforscht-wie-die-k',\n",
       " 'Viele SchlÃ¼ssel zum Erfolg â€“ Wie sich das Zessko vom Sprachen- zum Kompetenzzentrum entwickelte': 'https://www.uni-potsdam.de/de/nachrichten/detail/2021-04-06-viele-schluessel-zum-erfolg-wie-sich-das-zessko-vom-sprachen-zum-kompetenzzentrum-entwi',\n",
       " 'Im Interview: Sven Dinklage â€“ Im Einsatz als Liaison-Officer fÃ¼r die UP in Brasilien': 'https://www.uni-potsdam.de/de/nachrichten/detail/2021-03-30-im-interview-sven-dinklage-im-einsatz-als-liaison-officer-fuer-die-up-in-brasilien',\n",
       " 'â€žStudier was VernÃ¼nftiges!â€œ â€“ â€žSciVisToâ€œ-GrÃ¼nderin Franziska Schwarz Ã¼ber einen ungewÃ¶hnlichen Weg in die SelbststÃ¤ndigkeit': 'https://www.uni-potsdam.de/de/nachrichten/detail/2021-03-29-studier-was-vernuenftiges-scivisto-gruenderin-franziska-schwarz-ueber-einen',\n",
       " 'â€žIch wÃ¼rde meine Verteidigung auch lieber live durchfÃ¼hrenâ€œ â€“ Luise Krompholz macht ihren Abschluss an der Uni fern der Uni': 'https://www.uni-potsdam.de/de/nachrichten/detail/2021-03-25-ich-wuerde-meine-verteidigung-auch-lieber-live-durchfuehren-luise-krompholz-macht'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7b1a92",
   "metadata": {},
   "source": [
    "## Pagination\n",
    "You have probably realised that the articles presented on the first news page are not the entire collection of the University of Potsdam. Your goal is to retrieve a complete collection of all articles that are available on the university's website and you can easily apply your new knowledge in a repetive manner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241ac12e",
   "metadata": {},
   "source": [
    "16. Figure out how many pages containing articles content there are in total. You can do it manually by e.g. inspecting the URL when you proceed through the collection in your browser or by checking it programmatically by writing a `while` loop that continues until some condition, such as a status returned from your request, is violated. Make sure to include a short pause (1 second) in order not to overcharge the server that in some cases could lead to a temporary ban of your device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "eab3777a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 0.\n",
      "Scraping page 1.\n",
      "Scraping page 2.\n",
      "Scraping page 3.\n",
      "Scraping page 4.\n",
      "Scraping page 5.\n",
      "Scraping page 6.\n",
      "Scraping page 7.\n",
      "Scraping page 8.\n",
      "Scraping page 9.\n",
      "Scraping page 10.\n",
      "Scraping page 11.\n",
      "Scraping page 12.\n",
      "Scraping page 13.\n",
      "Scraping page 14.\n",
      "Scraping page 15.\n",
      "Scraping page 16.\n",
      "Scraping page 17.\n",
      "Scraping page 18.\n",
      "Scraping page 19.\n",
      "Scraping page 20.\n",
      "Scraping page 21.\n",
      "Scraping page 22.\n",
      "Scraping page 23.\n",
      "Scraping page 24.\n",
      "Scraping page 25.\n",
      "Scraping page 26.\n",
      "Scraping page 27.\n",
      "Scraping page 28.\n",
      "Scraping page 29.\n",
      "Scraping page 30.\n",
      "Scraping page 31.\n",
      "Scraping page 32.\n",
      "Scraping page 33.\n",
      "Scraping page 34.\n",
      "Scraping page 35.\n",
      "Scraping page 36.\n",
      "Scraping page 37.\n",
      "Scraping page 38.\n",
      "Scraping page 39.\n",
      "Scraping page 40.\n",
      "Scraping page 41.\n",
      "Scraping page 42.\n",
      "Scraping page 43.\n",
      "Scraping page 44.\n",
      "Scraping page 45.\n",
      "Scraping page 46.\n",
      "Scraping page 47.\n",
      "Scraping page 48.\n",
      "Scraping page 49.\n",
      "Scraping page 50.\n",
      "Scraping page 51.\n",
      "Scraping page 52.\n",
      "Scraping page 53.\n",
      "Scraping page 54.\n",
      "Scraping page 55.\n",
      "Scraping page 56.\n",
      "Scraping page 57.\n",
      "Scraping page 58.\n",
      "Scraping page 59.\n",
      "Scraping page 60.\n",
      "Scraping page 61.\n",
      "Scraping page 62.\n",
      "Scraping page 63.\n",
      "Scraping page 64.\n",
      "Scraping page 65.\n",
      "Scraping page 66.\n",
      "Scraping page 67.\n",
      "Scraping page 68.\n",
      "Scraping page 69.\n",
      "Scraping page 70.\n",
      "Scraping page 71.\n",
      "Scraping page 72.\n",
      "Scraping page 73.\n",
      "Scraping page 74.\n",
      "Scraping page 75.\n",
      "Scraping page 76.\n",
      "Scraping page 77.\n",
      "Scraping page 78.\n",
      "Scraping page 79.\n",
      "Scraping page 80.\n",
      "Scraping page 81.\n",
      "Scraping page 82.\n",
      "Scraping page 83.\n",
      "Scraping page 84.\n",
      "Scraping page 85.\n",
      "Scraping page 86.\n",
      "Scraping page 87.\n",
      "Scraping page 88.\n",
      "Scraping page 89.\n",
      "Scraping page 90.\n",
      "Scraping page 91.\n",
      "Scraping page 92.\n",
      "Scraping page 93.\n",
      "Scraping page 94.\n",
      "Scraping page 95.\n",
      "Scraping page 96.\n",
      "Scraping page 97.\n",
      "Scraping page 98.\n",
      "Scraping page 99.\n",
      "Scraping page 100.\n"
     ]
    }
   ],
   "source": [
    "# Long code block\n",
    "\n",
    "import time\n",
    "\n",
    "articles_links = []\n",
    "\n",
    "counter = 0\n",
    "\n",
    "test_seed = 'https://www.uni-potsdam.de/de/nachrichten/'\n",
    "test_html = requests.get(seed)\n",
    "status = test_html.status_code\n",
    "\n",
    "while status == 200:\n",
    "    \n",
    "    print('Scraping page ' + str(counter) + '.')\n",
    "    \n",
    "    if counter < 1:\n",
    "        \n",
    "        seed = 'https://www.uni-potsdam.de/de/nachrichten/'\n",
    "        \n",
    "        html = requests.get(seed)\n",
    "        \n",
    "        status = html.status_code\n",
    "        \n",
    "        soup = BeautifulSoup(html.text, \"html.parser\")\n",
    "        \n",
    "        news_list = list(map(lambda x: x, soup.select('.up-news-list-item')))\n",
    "        \n",
    "        link_list = []\n",
    "        title_list = []\n",
    "        \n",
    "        for link_num in range(len(news_list)):\n",
    "    \n",
    "            sub_link = news_list[link_num].findChild(\"a\")['href']\n",
    "            sub_title = news_list[link_num].findChild(\"a\")['title']\n",
    "    \n",
    "            if type(sub_link) is str and 'www' not in sub_link:\n",
    "        \n",
    "                link_list.append('https://www.uni-potsdam.de' + sub_link)\n",
    "                title_list.append(sub_title)\n",
    "        \n",
    "        articles_links.extend(link_list)\n",
    "        \n",
    "    elif counter >= 1:\n",
    "        \n",
    "        seed = 'https://www.uni-potsdam.de/de/nachrichten/page-{}'.format(str(counter+1))\n",
    "        \n",
    "        html = requests.get(seed)\n",
    "        \n",
    "        status = html.status_code\n",
    "        \n",
    "        soup = BeautifulSoup(html.text, \"html.parser\")\n",
    "        \n",
    "        news_list = list(map(lambda x: x, soup.select('.up-news-list-item')))\n",
    "        \n",
    "        link_list = []\n",
    "        title_list = []\n",
    "\n",
    "        for link_num in range(len(news_list)):\n",
    "    \n",
    "            sub_link = news_list[link_num].findChild(\"a\")['href']\n",
    "            sub_title = news_list[link_num].findChild(\"a\")['title']\n",
    "    \n",
    "            if type(sub_link) is str and 'www' not in sub_link:\n",
    "        \n",
    "                link_list.append('https://www.uni-potsdam.de' + sub_link)\n",
    "                title_list.append(sub_title)\n",
    "        \n",
    "        articles_links.extend(link_list)\n",
    "        \n",
    "    counter += 1\n",
    "    \n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a41ed5a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.uni-potsdam.de/de/nachrichten/detail/2021-04-15-studio-days-2021-digitale-studienorientierungswoche-der-staatlichen-brandenburgischen'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_links[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "978cae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('articles_links.txt', 'w') as output:\n",
    "    \n",
    "    output.writelines(\"%s\\n\" % line for line in articles_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3693f72e",
   "metadata": {},
   "source": [
    "17. Read in the JSON file you stored in step 17 and iterate over each hyperlink. Split the list into 4 evenly sized chunks and iterate over each chunk. In each iteration, obtain the HTML, parse it and identify the elements of the publication date, the contact, the contact's email address, the image's hyperlink/reference and the main text body's length. Note that some, or even all, of these elements may not be available. Define an appropriate data type for each field and append it **as a dictionary** in each iteration to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb711d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62804eab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b21f511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20924d64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cb0a672",
   "metadata": {},
   "source": [
    "## Asynchronous HTTP requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd30c75",
   "metadata": {},
   "source": [
    "18. Install the libaries `asyncio`, `aiohttp` and `tqdm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e85e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import bs4\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae44f47b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8932442e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230eeb5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900fe8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51495ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3956a3f",
   "metadata": {},
   "source": [
    "19. Find the missing link that appears in `articles_links_r` but not in `results_list` using a list comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c884c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747b1710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "604a6350",
   "metadata": {},
   "source": [
    "20. Install the `pandas` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdca886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793b6c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9e2e44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6c06fb8",
   "metadata": {},
   "source": [
    "21. Convert the `publication_date` into a `pandas` `datetime` object and plot a time series of published articles on a daily basis. Bonus: Aggregate the time series into monthly frequency. In which month-year were most articles published?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccbc26c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eacd95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01467d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5742df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f028e83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e531b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21851108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8f20f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72fe5dc6",
   "metadata": {},
   "source": [
    "22. Install the library `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d188ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f93e12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d38e1c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54488b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26aff088",
   "metadata": {},
   "source": [
    "23. Install the libraries `cufflinks` and `plotly`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5628f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481ef8d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4eeebf88",
   "metadata": {},
   "source": [
    "24. Install the `chart-studio` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa5e42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chart_studio\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42151f1",
   "metadata": {},
   "source": [
    "25. Log in to [Plotly Chart Studio](https://chart-studio.plotly.com/Auth/login/#/) and obtain your `Username` and `API key`. Store them both line-by-line in a .py file, e.g. name it \"plotly_config.py\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef9d86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly_config\n",
    "\n",
    "chart_studio.tools.set_credentials_file(username=plotly_config.Username, api_key=plotly_config.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597807c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Webscraping Workshop",
   "language": "python",
   "name": "webscraping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
